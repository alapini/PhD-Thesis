\section{Experimental results}
\label{sec:artin-benchmarks}

We discuss here the implementation of the algorithms of this Chapter
and some experimental results.

\paragraph{Implementation}
We packaged the algorithms of this paper in a \texttt{C++} library
called \texttt{FAAST} and made it available under the terms of the
\texttt{GNU GPL} software license from
\url{http://www.lix.polytechnique.fr/Labo/Luca.De-Feo/FAAST/}.

\texttt{FAAST} is implemented on top of the \texttt{NTL}
library~\cite{shoup2003ntl} which provides the basic univariate
polynomial arithmetic needed here. Our library handles three NTL
classes of finite fields: {\tt GF2} for $p=2$, {\tt zz\_p} for
word-size $p$ and {\tt ZZ\_p} for arbitrary $p$; this choice is made
by the user at compile-time through the use of \texttt{C++} templates
and the resulting code is thus quite efficient.  Optionally,
\texttt{NTL} can be combined with the \texttt{gf2x}
package~\cite{gf2x} for better performance in the $p=2$ case, as we
did in our experiments.

All the algorithms of
Sections~\ref{sec:fast-tower}--\ref{sec:pseudotrace-frobenius} are
faithfully implemented in \texttt{FAAST}. The algorithms
\alg{ApplyIsomorphism} and \alg{ApplyInverse} have slightly different
implementations \texttt{toUnivariate()} and \texttt{toBivariate()}
that allow more flexibility. Instead of being recursive algorithms
doing the change to and from the multivariate basis
$\basis{B}'_i=\{{x_0'}^{e_0}\cdots {x_i'}^{e_i}\}$, they only
implement the change to and from the bivariate basis
$\basis{D}'_i=\{{x_{i-1}}^{e_{i-1}}{x_i'}^{e_i}\}$ with $0\le
e_{i-1}<p^{i-1}d$ and $0\le e_i<p$. Equivalently, this amounts to
switch between the representations
\begin{equation}
  \wrt\U_i \quad\text{and}\quad
  \wrt\U_{i-1}[X_i']/(X_i'^p-X_i'-\gamma_{i-1}')
  \text{.}
\end{equation}
The same result as one call to \alg{ApplyIsomorphism} or
\alg{ApplyInverse} can be obtained by $i$ calls to
\texttt{toUnivariate()} and \texttt{toBivariate()}
respectively. However, in the case where several generic Artin-Schreier
towers, say $(\U_0',\ldots,\U_k')$ and $(\U_0'',\ldots,\U_k'')$, are
built using the algorithms of Section \ref{sec:couveignes-algorithm},
this allows to \emph{mix} the representations by letting the user
chose to switch to any of the bases $\{y_0^{e_0}\cdots y_i^{e_i}\}$
where $y_i$ is either $x_i'$ or $x_i''$. In other words this allows
the user to \emph{zig-zag} in the lattice of finite fields as in
Figure~\ref{fig:lattice}.

\begin{figure}
  \centering
  \begin{equation*}
    \xymatrix@C=1cm{
      & v\wrt\U_k \ar@{<--}@(r,u)[dr] \\
      \U_k'\ar@{-}[r]^{\sigma'} & \U_k\ar@{-}[d] & \U_k''\ar@{-}[l]_{\sigma''} \ar@{--}@(d,u)[dll]\\
      \U_{k-1}'\ar@{-}[r]^{\sigma'} \ar@{--}@(d,u)[drr] & \U_{k-1}\ar@{.}[d] & \U_{k-1}''\ar@{-}[l]_{\sigma''}\\
      \U_1'\ar@{-}[r]^{\sigma'} & \U_1\ar@{-}[d] & \U_1''\ar@{-}[l]_{\sigma''}\ar@{-->}[d]\\
      & \U_0 & *[r]{v\wrt\{{x_0}^{e_0}{x_1''}^{e_1}\cdots {x_{k-1}'}^{e_{k-1}}{x_k''}^{e_k}\}}
    }
  \end{equation*}
  \caption{An example of conversion from the univariate basis to a
    mixed multivariate basis.}
  \label{fig:lattice}
\end{figure}

Besides the algorithms presented in this paper, \texttt{FAAST} also
implements some algorithms described in
Chapter~\ref{cha:algor-small-char} for minimal polynomials, evaluation
and interpolation, as they are required for the isogeny computation
algorithm described there.

\paragraph{Experimental results.} We compare our timings with
those obtained in Mag\-ma~\cite{MAGMA} for similar questions.  All
results are obtained on an Intel Xeon E5430 (2.6GHz).


The experiments for the \texttt{FAAST} library were only made for the
classes \texttt{GF2} and \texttt{zz\_p}. The class \texttt{ZZ\_p} was
left out because all the primes that can be reasonably handled by our
library fit in one machine-word. In Magma, there exist several ways to
build field extensions:
\begin{description*}
\item [$\bullet$ {\tt quo<U|P>}] builds the quotient of the
  univariate polynomial ring $U$ by  $P \in U$
  (written magma(1) hereafter);
\item [$\bullet$ {\tt ext<k|P>}] builds the extension of the field $k$ by $P \in
  k[X]$ (written magma(2));
\item [$\bullet$ {\tt ext<k|p>}] builds an extension of degree $p$ of $k$
  (written magma(3)).
\end{description*}
We made experiments for each of these choices where this makes sense.

The parameters to our algorithms are $(p,d,k)$. Thus, our experiments
describe the following situations:

\begin{itemize}
\item {\em Increasing the height $k$.} Here we take $p=2$ and $d=1$ (that is,
  $\U_0=\F_2$); the $x$-coordinate gives the number of levels we
  construct and the $y$-coordinate gives timings in seconds, in {\em
    logarithmic} scale.

  This is done in Figure~\ref{fig:height}. We let the height of the
  tower increase and we give timings for (1) building the tower of
  Section~\ref{sec:fast-tower} and (2) computing an isomorphism with a
  random arbitrary tower as in Section~\ref{sec:couveignes-algorithm}.
  In the latter experiment, only the magma(2) approach was meaningful
  for Magma.
\item {\em Increasing the degree $d$ of $\U_0$.} Here we take $p=5$
  and we construct $2$ levels; the $x$-coordinate gives the degree $d
  = [\U_0:\F_p]$ and the $y$-coordinate gives timings in seconds.
  This is done in Figure~\ref{fig:p-d} (left).
\item {\em Increasing $p$.} Here we take $d=1$ (thus $\U_0=\F_p$) and
  we construct $2$ levels; the $x$-coordinate gives the characteristic
  $p$ and the $y$-coordinate gives timings in seconds.  This is done
  in Figure~\ref{fig:p-d} (right).
\end{itemize}



\begin{figure}
  \centering
%  \includegraphics[height=0.5\textwidth]{build1}
%  \includegraphics[height=0.5\textwidth]{iso1}
  
  \caption{Build time (left) and isomorphism time (right) with respect to tower height. Plot is in logarithmic scale.}
  \label{fig:height}
\end{figure}

\begin{figure}
  \centering
%  \includegraphics[height=0.5\textwidth]{build-d}
%  \includegraphics[height=0.5\textwidth]{build-p}
  
  \caption{Build times with respect to $d$ (left) and $p$ (right).}
  \label{fig:p-d}
\end{figure}

The timings of our code are significantly better for increasing height
or increasing $d$. Not surprisingly, for increasing $p$, the magma(1)
approach performs better than any other: the {\tt quo} operation
simply creates a residue class ring, regardless of the
(ir)reducibility of the modulus, so the timing for building two levels
barely depend on $p$. Yet, we notice that \texttt{FAAST} has
reasonable performances for characteristics up to about $p=50$.

In Tables~\ref{tab:arith-gf2} and~\ref{tab:arith-zzp} we provide some
comparative timings for the different arithmetic operations provided
by \texttt{FAAST}. The column ``Primitive'' gives the time taken to
build one level of the primitive tower (this includes the
precomputation of the data as described in
Subsection~\ref{sec:level-embedding:lift-up}); the other entries are
self-explanatory. Product and inversion are just wrappers around
\texttt{NTL} routines: in these operations we didn't observe any
overhead compared to the native \texttt{NTL} code. All the operations
stay within a factor of $30$ of the cost of multiplication, which is
satisfactory.

\begin{table}
  \centering
  \begin{tabular}{l | r | r | r | r | r | r | r}
    \small level & \small Primitive & \small Push-d. & \small Lift-up & \small Product & \small Inverse & \small apply $\sigma^{-1}$ & \small apply $\sigma$ \\
    \hline
     19 &  1.061 & 0.269 &  1.165 & 0.038 &  0.599 &  0.572 &  1.152\\
     20 &  2.381 & 0.538 &  2.554 & 0.076 &  1.430 &  1.146 &  2.333\\
     21 &  5.284 & 1.083 &  5.645 & 0.171 &  3.331 &  2.306 &  4.807\\
     22 & 11.747 & 2.202 & 12.595 & 0.430 &  7.730 &  4.811 & 10.051\\
     23 & 26.441 & 4.654 & 28.641 & 0.961 & 18.059 & 10.240 & 21.494\\
  \end{tabular}
  \caption{Some timings in seconds for arithmetics in a generic tower built over $\F_2$ using \texttt{GF2}.}
  \label{tab:arith-gf2}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{l | r | r | r | r | r | r | r}
    \small level & \small Primitive & \small Push-d. & \small Lift-up & \small Product & \small Inverse & \small $\sigma^{-1}$ & \small  $\sigma$ \\
    \hline
    18 &   9.159 &  0.514 &   8.278 &  0.321 &   6.432 &  2.379 &   6.624\\
    19 &  21.695 &  1.130 &  20.388 &  1.083 &  14.929 &  6.289 &  18.202\\
    20 &  49.137 &  3.058 &  48.605 &  2.444 &  33.986 & 10.716 &  32.493\\
    21 & 122.252 &  7.476 & 123.369 &  5.307 &  92.827 & 26.437 &  76.780\\
    22 & 275.110 & 15.832 & 279.338 & 10.971 & 210.680 & 47.956 & 134.167\\
  \end{tabular}
  \caption{Some timings in seconds for arithmetics in a generic tower built over $\F_2$ using \texttt{zz\_p}.}
  \label{tab:arith-zzp}
\end{table}


Finally, we mention the cost of precomputation. The precomputation of
the images of $\sigma$ as explained in
Section~\ref{sec:couveignes-algorithm} is quite expensive; most of it
is spent computing pseudotraces. Indeed it took one week to precompute
the data in Figure~\ref{fig:height} (right), while all the other data
can be computed in a few hours. There is still space for some minor
improvement in \texttt{FAAST}, mainly tweaking recursion thresholds
and implementing better algorithms for small and moderate input
sizes. Yet we think that only a major algorithmic improvement could
consistently speed up this phase.



% Local Variables: 
% mode:flyspell
% ispell-local-dictionary:"american"
% TeX-master: "../these"
% mode: Tex-PDF
% mode: reftex
% End: 
%
% LocalWords:  univariate isogeny Couveignes isogenies Artin Schreier
