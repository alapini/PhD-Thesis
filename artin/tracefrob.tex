\section{Frobenius and pseudotrace}
\label{sec:pseudotrace-frobenius}

In this section, we describe algorithms computing Frobenius
and pseudotrace operators, specific to the tower of
Section~\ref{sec:fast-tower}; they are the keys to the algorithms of
the next section.

The algorithms in this section and the next one closely follow
Couveignes'~\cite{couveignes00}. However, the latter assumed the
existence of a quasi-linear time algorithm for multiplication in some
specific towers in the multivariate basis $\basis{B}_i$ of
Subsection~\ref{ssec:rep}. To our knowledge, no such algorithm
exists. We use here the univariate basis $\basis{C}_i$ introduced
previously, which makes multiplication straightforward. However,
several push-down and lift-up operations are now required to
accommodate the recursive nature of the algorithm.

Our main purpose here is to compute the pseudotrace
\begin{equation}
  \label{eq:74}
  \PTr_{p^jd}:x\mapsto\sum_{\ell=0}^{p^jd-1}x^{p^{\ell}}
  \text{;}  
\end{equation}
we already gave an algorithm for this task in
Section~\ref{sec:modular-composition}, but in our context we can do
better. We start by describing how to compute values of the iterated
Frobenius operator $x \mapsto x^{p^n}$ by a recursive descent in the
tower.

We focus on computing the iterated Frobenius for $n<d$ or $n=p^jd$. In
both cases, similarly to~\eqref{eq:Kn}, we have:
\begin{gather}
  \label{eq:frobeniussum}
  x_i^{p^{n}} = x_i + \beta_{i-1,n}, \quad\text{with}\quad \beta_{i-1,n}=\PTr_{n}(\gamma_{i-1}).
\end{gather}
Assuming $\beta_{i-1,n}$ is known, the recursive step of the Frobenius
algorithm follows: starting from $v\wrt\U_i$, we first write
$v=v_0+\cdots+v_{p-1}x_i^{p-1}$, with $v_h\wrt\U_{i-1}$; by
\eqref{eq:frobeniussum} and the linearity of the Frobenius, we deduce
that
\begin{equation}
  \label{eq:frobeniuscomp}
\begin{array}{c}
v^{p^n}
  =\sum_{h=0}^{p-1} v_h^{p^n} \left(x_i + \beta_{i-1,n}\right)^{h}.
\end{array}
\end{equation}
Then, we compute all $v_h^{p^n}$ recursively; the final sum is
computed using Horner's scheme. Remark that this equations are not
limited to the case where $n<d$ or of the form $p^jd$: an arbitrary
$n$ would do as well. However, we impose this limitation since these
are the only values we need to compute $\PTr_{p^jd}$.

In the case $n=p^jd$, any $v \in \U_j$ is left invariant by this
Frobenius map, thus we stop the recursion when $i=j$, as there is
nothing left to do. In the case $n<d$, we stop the recursion when
$i=0$ and apply (see Section~\ref{sec:modular-composition}). We
summarize the two variants in one unique algorithm
\alg{IterFrobenius}.

\begin{algorithm}
  \caption{IterFrobenius} 
  \begin{algorithmic}[1]
    \REQUIRE $v$, $i$, $n$ with $v\wrt\U_i$ and $n<d$ or $n=p^jd$.
    \ENSURE $v^{p^n} \wrt \U_i$.
    \STATE \label{alg:frob:base} if $n=p^jd$ and $i \le j$, return $v$;
    \STATE \label{alg:frob:base2} if $i=0$, return $v^{p^n}$;
    \STATE \label{alg:frob:push} let $v_0 + v_1 x_i + \dots + v_{p-1} x_i^{p-1}=\text{\alg{Push-down}}(v)$;
    \STATE \label{alg:frob:rec} for $h \in [0,\dots,p-1]$, let $t_h = \alg{IterFrobenius}(v_h, i-1, n)$;
    \STATE let $F=0$;
    \STATE\label{alg:frob:T} for $h \in [p-1,\dots,0]$, let $F = t_h +  (x_i+\beta_{i-1,n})F$;
    \STATE \label{alg:frob:lift} return $\text{\alg{Lift-up}}(F)$.
  \end{algorithmic}
\end{algorithm}

As mentioned above, the algorithm requires the values $\beta_{i',n}$
for $i'<i$: we suppose that they are precomputed (the discussion of
how we precompute them follows).  To analyze costs, we use the
function $\Lift$ of Section~\ref{sec:level-embedding}.
\begin{theorem}
  \label{th:b-ifrob}
  On input $v\wrt\U_i$ and $n=p^jd$, algorithm \alg{IterFrobenius}
  correctly computes $v^{p^n}$ and takes time
  \begin{equation}
    \label{eq:95}
    O((i-j)\Lift(i))
    \text{.}
  \end{equation}
\end{theorem}
\begin{proof}
  Correctness is clear. We note $\Frob(i,j)$ for the complexity on
  inputs as in the statement; then $\Frob(0,j)=\cdots=\Frob(j,j)=0$
  because step~\ref{alg:frob:base} comes at no cost. For $i>j$, each
  pass through step~\ref{alg:frob:T} involves a multiplication by
  $x_i+\beta_{i-1,n}$, of cost of $O(p\Mult(p^{i-1}d))$, assuming
  $\beta_{i-1,n}\wrt \U_{i-1}$ is known. Altogether, we deduce the
  recurrence relation
  \begin{equation}
    \label{eq:75}
    \Frob(i,j) \le
    p\,\Frob(i-1,j)+2\,\Lift(i)+O(p^2\Mult(p^{i-1}d))
    \text{,}
  \end{equation}
  so $\Frob(i,j) \le p\,\Frob(i-1,j)+O(\Lift(i)),$ by assumptions on
  $\Mult$ and $\Lift$.  The conclusion follows, again by assumptions
  on $\Lift$.
\end{proof}

\begin{theorem}
  \label{th:l-ifrob}
  On input $v\wrt\U_i$ and $n<d$, algorithm \alg{IterFrobenius}
  correctly computes $v^{p^n}$ and takes time 
  \begin{equation}
    \label{eq:94}
    O(p^i\ModComp(d)\log (n) + i\Lift(i))
    \text{.}    
  \end{equation}
\end{theorem}
\begin{proof}
  The analysis is identical to the previous one, except that
  step~\ref{alg:frob:base2} is now executed instead of
  step~\ref{alg:frob:base} and this costs $O(\ModComp(d)\log (n))$ by
  the algorithm of Section~\ref{sec:modular-composition}. The
  conclusion follows by observing that step~\ref{alg:frob:base2} is
  repeated $p^i$ times.
\end{proof}

Next, we compute pseudotraces. We use the following relations, whose
verification is straightforward:
\begin{equation}
  \PTr_{n+m}(v) =
  \PTr_{n}(v) + \PTr_{m}(v)^{p^n}
  \text{,}\qquad
  \PTr_{nm}(v) =
  \sum_{h=0}^{m-1}\PTr_{n}(v)^{p^{hn}}
  \text{.}
\end{equation}
We give two \emph{divide-and-conquer} algorithms that do a slightly
different \emph{divide} step; each of them is based on one of the
previous formulas. The first one, \alg{LittlePseudotrace}, is meant to
compute $\PTr_d$. It follows a binary divide-and-conquer scheme
similar to the algorithm in Section~\ref{sec:modular-composition}. The
second one, \alg{Pseudotrace}, computes $\PTr_{p^jd}$ for $j>0$. It
uses the previous formula with $n=p^{j-1}d$ and $m=p$, computing
Frobenius-es for such $n$; when $j=0$, it invokes the first algorithm.


\begin{algorithm}
  \caption{LittlePseudotrace}
  \begin{algorithmic}[1]
    \REQUIRE $v$, $i$, $n$ with $v\wrt\U_i$ and $0<n\le d$.
    \ENSURE $T_{n}(v) \wrt \U_i$.
    \STATE \label{alg:lpseudo:base} if $n = 1$ return $v$;
    \STATE \label{alg:lpseudo:half} let $m = \lfloor n/2 \rfloor$;
    \STATE \label{alg:lpseudo:rec} let $t=$ {\sf LittlePseudotrace}($v$,
    $i$, $m$);
    \STATE \label{alg:lpseudo:frob} let $t=t+$ {\sf IterFrobenius}($t$, $i$, $m$);
    \STATE \label{alg:lpseudo:odd} if $n$ is odd, let $t=t+$ {\sf
      IterFrobenius}($v$, $i$, $n$);
    \STATE return $t$.
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Pseudotrace}
  \begin{algorithmic}[1]
    \REQUIRE $v$, $i$, $j$ with $v\wrt\U_i$.
    \ENSURE $T_{p^jd}(v) \wrt \U_i$.
    \STATE \label{alg:pseudo:base} if $j = 0$ return {\sf LittlePseudotrace}($v$, $d$);
    \STATE \label{alg:pseudo:rec} $t_0=${\sf Pseudotrace}($v, i, j-1$);
    \STATE \label{alg:pseudo:frob}for $h\in [1,\dots,p-1]$, let $t_h=\text{\alg{IterFrobenius}}(t_{h-1}, i, j-1)$;
    \STATE \label{alg:pseudo:sum}return $t_0 + t_1 + \cdots + t_{p-1}$.
  \end{algorithmic}
\end{algorithm}

\begin{theorem}
  \label{th:l-pseudo}
  Algorithm \alg{LittlePseudotrace} is correct and takes time
  \begin{equation}
    \label{eq:96}
    O(p^i\ModComp(d)\log^2 (n) + i \Lift(i)\log (n))
    \text{.}
  \end{equation}
\end{theorem}
\begin{proof}
  Correctness is clear. For the cost analysis, we write $\Ptr(i,n)$
  for the cost on input $i$ and $n$, so $\Ptr(i,1)=O(1)$.  For $n>1$,
  step \ref{alg:lpseudo:rec} costs $\Ptr(i,\lfloor n/2 \rfloor)$,
  steps~\ref{alg:lpseudo:frob} and~\ref{alg:lpseudo:odd} cost both
  \begin{equation}
    \label{eq:100}
    O(p^i\ModComp(d)\log^2 (n) + i \Lift(i))
  \end{equation}
  by Theorem~\ref{th:l-ifrob}. This gives
  \begin{equation}
    \label{eq:98}
    \Ptr(i,n) = \Ptr(i,\lfloor
    n/2\rfloor) +O(p^i\ModComp(d)\log^2 (n) + i \Lift(i))
    \text{,}
  \end{equation}
  and thus
  \begin{equation}
    \label{eq:99}
    \Ptr(i,n) \in O(p^i\ModComp(d)\log^2 (n) + i \Lift(i)\log n)
    \text{.}
  \end{equation}
\end{proof}


\begin{theorem}
  \label{th:b-pseudo}
  Algorithm \alg{Pseudotrace} is correct and takes time
  \begin{equation}
    \label{eq:97}
    \Ptr(i)=O((pi+\log (d))i\Lift(i)+p^i\ModComp(d)\log^2 (d))    
  \end{equation}
  for $j \le
  i$.
\end{theorem}
\begin{proof}
  Correctness is clear. For the cost analysis, we write $\Ptr(i,j)$
  for the cost on input $i$ and $j$, so theorem~\ref{th:l-pseudo}
  gives 
  \begin{equation}
    \label{eq:101}
    \Ptr(i,0)=O(p^i\ModComp(d)\log^2 (d) + i \Lift(i)\log(d))
    \text{.} 
  \end{equation}
  For $j>0$, step \ref{alg:pseudo:rec} costs $\Ptr(i,j-1)$,
  step~\ref{alg:pseudo:frob} costs $O(p i \Lift(i))$ by
  Theorem~\ref{th:b-ifrob} and step~\ref{alg:pseudo:sum} costs
  $O(p^{i+1}d)$. This gives 
  \begin{equation}
    \label{eq:102}
    \Ptr(i,j) = \Ptr(i,j-1) +O(p i \Lift(i))
    \text{,}
  \end{equation}
  and thus 
  \begin{equation}
    \label{eq:103}
    \Ptr(i,j) \in O(pij{\sf L}(i) + \Ptr(i,0))
    \text{.}
  \end{equation}
\end{proof}

The cost is thus $O(p^{i+2}d+p^i\ModComp(d))$, up to logarithmic
factors, for an input and output size of $p^id$: this time, due to
modular compositions in $\U_0$, the cost is not linear in $d$.

Finally, let us discuss precomputations. On input $v$, $i$, $d$, the
algorithm \alg{LittlePseudotrace} makes less than $2\log d$ calls to
\alg{IterFrobenius($x$,$i$,$n$)} for some value $x\in\U_i$ and for
$n\in N$ where the set $N$ only depends on $d$. When we construct
$\U_{i+1}$, we compute (only) all $\beta_{i,n}=\PTr_{n}(\gamma_i)
\wrt\U_i$, for increasing $n\in N$, using the \alg{LittlePseudotrace}
algorithm. The inner calls to \alg{IterFrobenius} only use
pseudotraces that are already known. Besides, a single call to
\alg{LittlePseudotrace}$(\gamma_i,i,d)$ actually computes {\em all}
$\PTr_{n}(\gamma_i)$ in time 
\begin{equation}
  \label{eq:104}
  O(p^i\ModComp(d)\log^2 d + i
  \Lift(i)\log d)
  \text{.}
\end{equation}
Same goes for the precomputation of all
$\beta_{i,p^jd}=\PTr_{p^jd}(\gamma_i) \wrt\U_i$, for $j\le i$, using
the \alg{Pseudotrace} algorithm: this costs $\Ptr(i)$. Observe that in
total we only store $O(k^2 + k\log d)$ elements of the tower, thus the
space requirements are quasi-linear.

\begin{remark}
  A dynamic programming version of~\alg{LittlePseudotrace} as
  in Section~\ref{sec:modular-composition} would only precompute
  $\beta_{i,2^e}$ for $2^e<d$, thus reducing the storage from $2\log
  d$ to $\lfloor\log d\rfloor$ elements. This would also allow to
  compute $\PTr_n$ for any $n<d$ without needing any further
  precomputation. Using this algorithm and a decomposition of $n>d$ as
  $n=r+\sum_jc_jp^jd$ with $r<d$ and $c_j<p$, one could also compute
  $T_{n}$ and $x^{p^n}$ for any $n$ at essentially the same cost. We
  omit these improvements since they are not essential to the next
  section.
\end{remark}

% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% TeX-master: "../these"
% mode: TeX-PDF
% mode: reftex
% End:
%
% LocalWords:  Schreier Artin pseudotrace frobenius bivariate memoization
% LocalWords:  precomputed precomputation precompute precomputations Couveignes
% LocalWords:  univariate pseudotraces
