\section{Frobenius and pseudotrace}
\label{sec:pseudotrace-frobenius}

In this section, we describe algorithms computing Frobenius
and pseudotrace operators, specific to the tower of
Section~\ref{sec:fast-tower}; they are the keys to the algorithms of
the next section.

The algorithms in this section and the next one closely follow
Couveignes'~\cite{Couveignes00}. However, the latter assumed the
existence of a quasi-linear time algorithm for multiplication in some
specific towers in the multivariate basis $\bB_i$ of
Subsection~\ref{ssec:rep}. To our knowledge, no such algorithm
exists. We use here the univariate basis $\bC_i$ introduced
previously, which makes multiplication straightforward. However,
several push-down and lift-up operations are now required to
accommodate the recursive nature of the algorithm.

Our main purpose here is to compute the pseudotrace
${\PTr_{p^jd}:x\mapsto\sum_{\ell=0}^{p^jd-1}x^{p^{\ell}}}$. First, however,
we describe how to compute values of the iterated Frobenius operator
$x \mapsto x^{p^n}$ by a recursive descent in the tower.

We focus on computing the iterated Frobenius for $n<d$ or $n=p^jd$. In
both cases, similarly to~\eqref{eq:Kn}, we have:
\begin{gather}
  \label{eq:frobeniussum}
  x_i^{p^{n}} = x_i + \beta_{i-1,n}, \quad\text{with}\quad \beta_{i-1,n}=\PTr_{n}(\gamma_{i-1}).
\end{gather}
Assuming $\beta_{i-1,n}$ is known, the recursive step of the Frobenius
algorithm follows: starting from $v\wrt\U_i$, we first write
$v=v_0+\cdots+v_{p-1}x_i^{p-1}$, with $v_h\wrt\U_{i-1}$; by
\eqref{eq:frobeniussum} and the linearity of the Frobenius, we deduce
that
\begin{equation*}
  \label{eq:frobeniuscomp}
\begin{array}{c}
v^{p^n}
  =\sum_{h=0}^{p-1} v_h^{p^n} \left(x_i + \beta_{i-1,n}\right)^{h}.
\end{array}
\end{equation*}
Then, we compute all $v_h^{p^n}$ recursively; the final sum is
computed using Horner's scheme. Remark that this variant is not
limited to the case where $n<d$ or of the form $p^jd$: an arbitrary
$n$ would do as well. However, we impose this limitation since these
are the only values we need to compute $\PTr_{p^jd}$.

In the case $n=p^jd$, any $v \in \U_j$ is left invariant by this
Frobenius map, thus we stop the recursion when $i=j$, as there is
nothing left to do. In the case $n<d$, we stop the recursion when
$i=0$ and apply~\cite[Algorithm 5.2]{vzGS92}. We summarize the two
variants in one unique algorithm \alg{IterFrobenius}.
\begin{algorithm}
  {IterFrobenius} 
  {$v$, $i$, $n$ with $v\wrt\U_i$ and $n<d$ or $n=p^jd$.}  
  {$v^{p^n} \wrt \U_i$.}
\item \label{alg:frob:base} if $n=p^jd$ and $i \le j$, return $v$
\item \label{alg:frob:base2} if $i=0$, return $v^{p^n}$
\item \label{alg:frob:push} let $v_0 + v_1 x_i + \dots + v_{p-1} x_i^{p-1}=\text{\alg{Push-down}}(v)$
\item \label{alg:frob:rec} for $h \in [0,\dots,p-1]$, let $t_h = \alg{IterFrobenius}(v_h, i-1, n)$
\item let $F=0$
\item\label{alg:frob:T} for $h \in [p-1,\dots,0]$, let $F = t_h +  (x_i+\beta_{i-1,n})F$
\item \label{alg:frob:lift} return $\text{\alg{Lift-up}}(F)$
\end{algorithm}

As mentioned above, the algorithm requires the values $\beta_{i',n}$
for $i'<i$: we suppose that they are precomputed (the discussion of
how we precompute them follows).  To analyze costs, we use the
function $\L$ of Section~\ref{sec:level-embedding}.
\begin{theorem}
  \label{th:b-ifrob}
  On input $v\wrt\U_i$ and $n=p^jd$, algorithm \alg{IterFrobenius}
  correctly computes $v^{p^n}$ and takes time $O((i-j)\L(i))$.
\end{theorem}
\begin{proof} Correctness is clear. We note $\Frob(i,j)$ for the complexity
on inputs as in the statement; then $\Frob(0,j)=\cdots=\Frob(j,j)=0$
because step~\ref{alg:frob:base} comes at no cost. For $i>j$, each
pass through step~\ref{alg:frob:T} involves a multiplication by
$x_i+\beta_{i-1,n}$, of cost of $O(p\Mult(p^{i-1}d))$, assuming
$\beta_{i-1,n}\wrt \U_{i-1}$ is known. Altogether, we deduce the
recurrence relation
$$\Frob(i,j) \le
p\,\Frob(i-1,j)+2\,\L(i)+O(p^2\Mult(p^{i-1}d)),$$ so $\Frob(i,j) \le
p\,\Frob(i-1,j)+O(\L(i)),$ by assumptions on $\Mult$ and $\L$.  The
conclusion follows, again by assumptions on $\L$.\end{proof}

\begin{theorem}
  \label{th:l-ifrob}
  On input $v\wrt\U_i$ and $n<d$, algorithm \alg{IterFrobenius}
  correctly computes $v^{p^n}$ and takes time $O(p^i\ModComp(d)\log
  (n) + i\L(i))$.
\end{theorem}
\begin{proof} The analysis is identical to the previous one, except that
step~\ref{alg:frob:base2} is now executed instead of
step~\ref{alg:frob:base} and this costs $O(\ModComp(d)\log (n))$
by~\cite[Lemma 5.3]{vzGS92}. The conclusion follows by observing that
step~\ref{alg:frob:base2} is repeated $p^i$ times. \end{proof}


\smallskip

Next, we compute pseudotraces. We use the following relations, whose
verification is straightforward:
\begin{equation*}
  \PTr_{n+m}(v) =
  \PTr_{n}(v) + \PTr_{m}(v)^{p^n}
  \text{,}\qquad
  \PTr_{nm}(v) =
  \sum_{h=0}^{m-1}\PTr_{n}(v)^{p^{hn}}
  \text{.}
\end{equation*}
We give two \emph{divide-and-conquer} algorithms that do a slightly
different \emph{divide} step; each of them is based on one of the
previous formulas. The first one, \alg{LittlePseudotrace}, is meant to
compute $\PTr_d$. It follows a binary divide-and-conquer scheme
similar to~\cite[Algorithm~5.2]{vzGS92}. The second one,
\alg{Pseudotrace}, computes $\PTr_{p^jd}$ for $j>0$. It uses the
previous formula with $n=p^{j-1}d$ and $m=p$, computing Frobenius-es
for such $n$; when $j=0$, it invokes the first algorithm.


\begin{algorithm}
  {LittlePseudotrace}
  {$v$, $i$, $n$ with $v\wrt\U_i$ and $0<n\le d$.}  
  {$T_{n}(v) \wrt \U_i$.}
\item \label{alg:lpseudo:base} if $n = 1$ return $v$
\item \label{alg:lpseudo:half} let $m = \lfloor n/2 \rfloor$
\item \label{alg:lpseudo:rec} let $t=$ {\sf LittlePseudotrace}($v$,
  $i$, $m$)
\item \label{alg:lpseudo:frob} let $t=t+$ {\sf IterFrobenius}($t$, $i$, $m$)
\item \label{alg:lpseudo:odd} if $n$ is odd, let $t=t+$ {\sf
    IterFrobenius}($v$, $i$, $n$)
\item return $t$
\end{algorithm}
\begin{algorithm}
  {Pseudotrace}
  {$v$, $i$, $j$ with $v\wrt\U_i$.}  
  {$T_{p^jd}(v) \wrt \U_i$.}
\item \label{alg:pseudo:base} if $j = 0$ return {\sf LittlePseudotrace}($v$, $d$)
\item \label{alg:pseudo:rec} $t_0=${\sf Pseudotrace}($v, i, j-1$)
\item \label{alg:pseudo:frob}for $h\in [1,\dots,p-1]$, let $t_h=\text{\alg{IterFrobenius}}(t_{h-1}, i, j-1)$
\item \label{alg:pseudo:sum}return $t_0 + t_1 + \cdots + t_{p-1}$
\end{algorithm}

\begin{theorem}
  \label{th:l-pseudo}
  Algorithm \alg{LittlePseudotrace} is correct and takes time
  $O(p^i\ModComp(d)\log^2 (n) + i \L(i)\log (n))$.
\end{theorem}
\begin{proof} Correctness is clear. For the cost analysis, we write
$\Ptr(i,n)$ for the cost on input $i$ and $n$, so $\Ptr(i,1)=O(1)$.
For $n>1$, step \ref{alg:lpseudo:rec} costs $\Ptr(i,\lfloor n/2
\rfloor)$, steps~\ref{alg:lpseudo:frob} and~\ref{alg:lpseudo:odd} cost
both $O(p^i\ModComp(d)\log^2 (n) + i \L(i))$ by
Theorem~\ref{th:l-ifrob}. This gives $\Ptr(i,n) = \Ptr(i,\lfloor
n/2\rfloor) +O(p^i\ModComp(d)\log^2 (n) + i \L(i))$, and thus $\Ptr(i,n)
\in O(p^i\ModComp(d)\log^2 (n) + i \L(i)\log n)$.\end{proof}


\begin{theorem}
  \label{th:b-pseudo}
  Algorithm \alg{Pseudotrace} is correct and takes time
  $\Ptr(i)=O((pi+\log (d))i\L(i)+p^i\ModComp(d)\log^2 (d))$ for $j \le
  i$.
\end{theorem}
\begin{proof} Correctness is clear. For the cost analysis, we write
$\Ptr(i,j)$ for the cost on input $i$ and $j$, so
theorem~\ref{th:l-pseudo} gives $\Ptr(i,0)=O(p^i\ModComp(d)\log^2 (d) +
i \L(i)\log (d))$. For $j>0$, step \ref{alg:pseudo:rec} costs
$\Ptr(i,j-1)$, step~\ref{alg:pseudo:frob} costs $O(p i \L(i))$ by
Theorem~\ref{th:b-ifrob} and step~\ref{alg:pseudo:sum} costs
$O(p^{i+1}d)$. This gives $\Ptr(i,j) = \Ptr(i,j-1) +O(p i \L(i))$, and
thus $\Ptr(i,j) \in O(pij{\sf L}(i) + \Ptr(i,0))$. \end{proof}

\smallskip

The cost is thus $O(p^{i+2}d+p^i\ModComp(d))$, up to logarithmic
factors, for an input and output size of $p^id$: this time, due to
modular compositions in $\U_0$, the cost is not linear in $d$.

\smallskip

Finally, let us discuss precomputations. On input $v$, $i$, $d$, the
algorithm \alg{LittlePseudotrace} makes less than $2\log d$ calls to
\alg{IterFrobenius($x$,$i$,$n$)} for some value $x\in\U_i$ and for
$n\in N$ where the set $N$ only depends on $d$. When we construct
$\U_{i+1}$, we compute (only) all $\beta_{i,n}=\PTr_{n}(\gamma_i)
\wrt\U_i$, for increasing $n\in N$, using the \alg{LittlePseudotrace}
algorithm. The inner calls to \alg{IterFrobenius} only use
pseudotraces that are already known. Besides, a single call to
\alg{LittlePseudotrace}$(\gamma_i,i,d)$ actually computes {\em all}
$\PTr_{n}(\gamma_i)$ in time $O(p^i\ModComp(d)\log^2 d + i \L(i)\log
d)$. Same goes for the precomputation of all
$\beta_{i,p^jd}=\PTr_{p^jd}(\gamma_i) \wrt\U_i$, for $j\le i$, using
the \alg{Pseudotrace} algorithm: this costs $\Ptr(i)$. Observe that in
total we only store $O(k^2 + k\log d)$ elements of the tower, thus the
space requirements are quasi-linear.

\paragraph*{\bf Remark.}  A dynamic programming version
of~\alg{LittlePseudotrace} as in~\cite[Algorithm~5.2]{vzGS92} would
only precompute $\beta_{i,2^e}$ for $2^e<d$, thus reducing the storage
from $2\log d$ to $\lfloor\log d\rfloor$ elements. This would also
allow to compute $\PTr_n$ for any $n<d$ without needing any further
precomputation. Using this algorithm and a decomposition of $n>d$ as
$n=r+\sum_jc_jp^jd$ with $r<d$ and $c_j<p$, one could also compute
$T_{n}$ and $x^{p^n}$ at essentially the same cost. We omit these
improvements since they are not essential to the next Section.


% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% TeX-master: "artin"
% mode: TeX-PDF
% End:
%
% LocalWords:  Schreier Artin pseudotrace frobenius bivariate memoization
% LocalWords:  precomputed precomputation precompute precomputations Couveignes
% LocalWords:  univariate pseudotraces
