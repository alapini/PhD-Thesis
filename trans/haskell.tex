\section{From circuits to function-level programming}
\label{sec:fp}
\lstset{language=haskell}

In Section \ref{sec:circuits} we saw that the transposition theorem
holds for uniform circuit families.  Informally, an uniform circuit
family can be simulated in a BSS-like model \cite{BSS} such as a
Turing machine with an additional input/output tape where each cell
contains an element of $R$. Then the transposition theorem can be
extended to this context and it is easy to prove that some fundamental
measures such as space and time complexity are preserved by it. This
kind of approach has been used in \cite{BoLeSc03}.

We won't go further in defining a model and proving a transposition
theorem as this is just matter of posing the right definitions and
deriving the (boring) consequences. Here, instead, we are interested
in the real world scenario of transposing a computer program written
in a general purpose programming language. This section studies how an
uniform circuit family can be efficiently simulated in the Haskell
programming language and how its transposition can automatically be
obtained. Nevertheless, this approach has some limitations that we
will address in the next sections.

As we already pointed out in Section \ref{sec:circuits}, evaluation
(and co-evaluation) of arithmetic circuits can be formally defined by
means of a category with finite products (and coproducts). Arithmetic
circuits over $\Tbasis$, in particular, are defined by means of an
\emph{additive category}, that is a category such that $\hom$ sets are
abelian groups, it has \emph{zero morphisms} and it has all finite
\emph{biproducts}.

It can be proven \cite[VIII.2]{McLane} that in an additive category
finite products and coproducts are naturally isomorphic to biproducts.
This is the key argument for the proof of our lemma \ref{th:coeval}
and ultimately leads to the transposition theorem in the special case
of $\RMod{R}$.

Modern functional languages too are constructed around the concept of
category: roughly, the types of the language are viewed as objects and
programs as arrows. In this setting, categories are required to be
\emph{Cartesian closed}. This allows to perform \emph{partial
  evaluation} of a function, an operation known as
\emph{currying}. Examples of Cartesian closed categories are
$\mathsf{Set}$ and $\mathsf{Hask}$ --the category of Haskell types--.

Cartesian closed categories cannot be additive, thus it may seem that
our attempts to natively express circuits in functional languages are
doomed. However the Haskell type system is powerful enough to
represent some categories inside it, in particular subcategories of
$\mathsf{Hask}$. It provides a \emph{type class} \lstinline+Category+,
that we reproduce here --following \cite{Yor09}, we use an infix
operator \lstinline+(~>)+ instead of a prefix one as in the standard
Haskell library--.

\begin{lstlisting}
  class Category (~>) => where
    id :: (a ~> a)
    (.) :: (b ~> c) -> (a ~> b) -> (a ~> c)
\end{lstlisting}

In order to behave as a category, an instance of this class shall form
a monoid for the operation \lstinline+(.)+, with \lstinline+id+ being
the identity element. Now this class can be extended to model additive
categories: we first define a class that mimics \emph{Ab-categories},
or \emph{preadditive} categories, that is categories whose $\hom$ sets
are abelian groups.

\begin{lstlisting}
  class Category (~>) => AbCategory (~>) where
    zeroArrow :: (a ~> b)
    (<+>) :: (a ~> b) -> (a ~> b) -> (a ~> b)
\end{lstlisting}
To behave as an Ab-category, an instance shall form an abelian group
for the operation \lstinline|<+>|, with \lstinline+zero+ being the
identity element; it shall also obey a \emph{bilinear law}:
\begin{lstlisting}
  (f <+> g).(h <+> i) = f.h <+> f.i <+> g.h <+> g.i
\end{lstlisting}

Now we give one possible definition of a class that mimics additive
categories.
\begin{lstlisting}
  class AbCategory (~>) => AdditiveCategory (~>) where
    (&&&) :: (a ~> b) -> (a ~> c) -> (a ~> (b, c))
    (|||) :: (a ~> c) -> (b ~> c) -> ((a, b) ~> c)

  first f = f <**> zeroArrow
  second f = zeroArrow <**> f
  left f = f <++> zeroArrow
  right f = zeroArrow <++> f
  f *** g = (first f) ||| (second g)
\end{lstlisting}
For an instance to behave as an additive category it shall satisfy
\begin{lstlisting}
  id *** id = id
  zeroArrow &&& zeroArrow = zeroArrow ||| zeroArrow = zeroArrow
  (f &&& g) <+> (f' &&& g') = (f <+> f') &&& (g <+> g')
  (f ||| g) <+> (f' ||| g') = (f <+> f') ||| (g <+> g')
  (f ||| g) &&& (f' ||| g') = (f &&& f') ||| (g &&& g')
  (f ||| g)  .  (f' &&& g') = f.f' <+> g.g'
\end{lstlisting}

Haskell programmers may have recognized a familiar pattern:
\emph{arrows}. Arrows were introduced in \cite{Hug00} as a
generalization of \emph{monads}, they have been successfully applied
to many different settings such as, for example, solving ordinary
differential equations \cite{LH10}. They are usually understood as
circuits \cite{Pat01}: the standard library class \lstinline+Arrow+ is
roughly equivalent to evaluation of an arithmetic circuit in
$\mathsf{Hask}$ (or $\mathsf{Set}$), while \lstinline+ArrowChoice+ is
roughly equivalent to co-evaluation.

Our \lstinline+AdditiveCategory+ shares similarities with the standard
classes \lstinline+Arrow+, \lstinline+ArrowChoice+,
\lstinline+ArrowZero+ and \lstinline+ArrowPlus+. In particular, it is
equivalent to evaluation of an arithmetic circuit in an additive
category and, by lemma \ref{th:coeval}, to co-evaluation.

An arrow expression is an expression formed uniquely from elementary
arrows and the combinators of \lstinline+AdditiveCategory+. Given an
arrow expression, it is trivial to form its dual: one substitutes
\lstinline|first| with \lstinline|left|, \lstinline|second| with
\lstinline|right|, \lstinline|&&&| with \lstinline&|||& and changes
any \lstinline|f.g| into \lstinline|g.f|. This corresponds to forming
the dual circuit as in definition \ref{def:dual}, thus if
\lstinline+AdditiveCategory+ is instantiated with arrows that
correspond to the elements of the basis\footnote{It is actually enough
  to create the elementary arrows that correspond to $*_a$ for any
  $a\in R$. The combinators \lstinline+&&&+ and \lstinline+|||+
  already imply $+$ and $\hub$.} $\Tbasis$, one obtains the transposed
circuit as in theorem \ref{th:tellegen}. Also notice that Haskell
defines a \lstinline+do+-notation \cite{Pat01} to write down arrow
expressions more conveniently. Dualizing this notation boils down to
applying the transposition algorithm given in Section \ref{todo}.

By writing Haskell functions that return arrows, or, more generally,
functions that have arbitrary types involving arrows, one can express
circuit families and apply the transposition theorem to them by
dualizing each arrow expression appearing in the computation. Figure
\ref{fig:karahask} shows an example of Karatsuba multiplication
written using this technique.

\begin{figure}
  \centering
  
  \caption{The left-linear Karatsuba algorithm.}
  \label{fig:karahask}
\end{figure}


One limitation to this approach is that it cannot be implemented
inside Haskell. As we have defined them, arrows do not remember their
history: the arrow \lstinline+f.g+ is a new arrow that knows nothing
about the pieces that compose it, thus no Haskell function can
transform it in \lstinline+g.f+. There are three solutions to this:
\begin{enumerate}
\item Define \emph{biarrows} instead of arrows \cite{ASWEP05}. This
  way the dual is computed as a side effect of the computation of the
  arrow. The main advantage of this approach is that it is easy to
  implement, its main disadvantage is that it is not compatible with
  the \lstinline+do+ notation, as observed in \cite{ASWEP05}. Another
  minor disadvantage is that the dualization is not transparent as it
  does not happen at the level of the arrow expression, but inside its
  computation.
\item Write a precompiler for Haskell that dualizes arrow
  expressions. The great advantage of this approach is that it permits
  to treat \lstinline+do+-expressions.
\item Implement arrows at the type-level, instead of the function
  level, by defining a type that describes circuits. However this
  approach is not realistic because of its poor efficiency.
\end{enumerate}

A second, fundamental, limitation is that this approach requires the
user to explicitly identify the linear computations by wrapping them
in arrows. This process may be almost as hard as transposing a program
by hand as done by \cite{BoLeSc03} and the resulting code may be
difficult to read (see figure \ref{fig:karahask}). The next Section
studies an alternative approach where the user if freed from the
burden of \emph{linearizing} the program.



% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% mode:TeX-PDF
% TeX-master: "transAL"
% End:
%
