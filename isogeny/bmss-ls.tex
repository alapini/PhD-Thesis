%% these.tex
%% Copyright 2010 Luca De Feo
%% All rights reserved


\section{BMSS}
\label{sec:bmss}
In this section we present the BMSS
algorithm~\cite{bostan+morain+salvy+schost08} to compute isogenies of
degree $\ell\ne p$ in characteristic $0$ or $p\gg\ell$. It takes as
input the integer $\ell$ and two elliptic curves $E$ and $E'$ over a
finite field $\F_q$ defined by \emph{normalized models} (see
definitions \hyperref[def:canon-isog]{below}). It outputs the explicit
isogeny using $O(\Mult(\ell)\log\ell)$ operations in $\F_q$, or
$O(\Mult(\ell))$ in case the sum of the abscissas of the kernel of the
isogeny is known.

\pdfmcthree{Adapted to the case p=3.}  Because of the assumption on
the characteristic, we can assume $p\ne 2$ and the curves to be in
the form
\begin{equation}
  \label{eq:140}
  \begin{aligned}
    E \;&:\: y^2 = x^3 + a_2x^2 + a_4x + a_6\text{,}\\
    E'\;&:\; y^2 = x^3 + a_2'x^2 + a_4'x + a_6'\text{.}
  \end{aligned}
\end{equation}
Then, any isogeny $\I:E\ra E'$ of odd degree is of the form
\begin{equation}
  \label{eq:149}
  \I(x,y) = \left(\frac{g(x)}{h(x)},cy\left(\frac{g(x)}{h(x)}\right)'\right)
  \text{,}
\end{equation}
with $c\in\clot{\K}$, and $g,h$ monic polynomials in $\clot{\K}[X]$
(this is a consequence of \titleref{sec:velu-formulas}).

\begin{definition}[Normalized isogeny]
  \label{def:canon-isog}
  An explicit isogeny given by Eq.\ifafive\ \else~\fi\eqref{eq:149} is said to be
  \index{normalized~isogeny}\index{isogeny!normalized}\emph{normalized}
  if $c=1$. 

  Given two $\ell$-isogenous curves $E$ and $E'$, Weierstrass
  equations for them such that the explicit $\ell$-isogeny
  $\I:E\ra E'$ is normalized, are called
  \index{normalized~model}\emph{$\ell$-normalized models} for those
  elliptic curves.
\end{definition}

\pdfmctwo{Swapped sentences in this paragraph in order to stress that
  the differential equation satisfied by the isogeny comes from Vélu's
  formulas.} It is noteworthy that Vélu formulas output normalized
models and a normalized isogeny. Normalized models naturally arise in
point counting: in fact in the Schoof-Elkies-Atkin
algorithm~\cite{atkin88,elkies98,schoof95} one factors the modular
polynomial $\Modpol_\ell$ to obtain $j$-invariants of curves
$\ell$-isogenous to $E$. As a consequence of Vélu formulas, it is
possible to obtain normalized models for such curves from the
knowledge of the partial derivatives of $\Modpol_\ell$.  Details can
be found in~\cite{schoof95,morain95,elkies98,lercier-algorithmique}.

\pdfmcthree{Modified equation to work when p=3.}
Our goal is to compute the rational fraction $\frac{g(x)}{h(x)}$. From
the fact that $\I$ is normalized and from Eq.~\eqref{eq:149} we deduce
\ifafive
\begin{multline}
  \label{eq:166}
  (x^3 + a_2x^2 + a_4x + a_6){\left(\frac{g(x)}{h(x)}\right)'}^2 =\\
  \left(\frac{g(x)}{h(x)}\right)^3 + a_2'\left(\frac{g(x)}{h(x)}\right)^2 + a_4'\frac{g(x)}{h(x)} + a_6'
  \text{.}
\end{multline}
\else
\begin{equation}
  \label{eq:166}
  (x^3 + a_2x^2 + a_4x + a_6){\left(\frac{g(x)}{h(x)}\right)'}^2 =
  \left(\frac{g(x)}{h(x)}\right)^3 + a_2'\left(\frac{g(x)}{h(x)}\right)^2 + a_4'\frac{g(x)}{h(x)} + a_6'
  \text{.}
\end{equation}
\fi
The key idea is to find a power series solution to this differential
equation and then deduce the rational fraction.

\pdfmcthree{Modified equation to work when p=3.}  However, we do not
know the initial condition at $0$, and we cannot look for an expansion
at infinity either, because the degree of $g$ is greater than the
degree of $h$.  Instead we set
\begin{equation}
  \label{eq:167}
  S(x) = \sqrt{\frac{h(1/x^2)}{g(1/x^2)}}
  \quad\Leftrightarrow\quad
  \frac{g(x)}{h(x)} = \frac{1}{S(1/\sqrt{x})^2}
  \text{,}
\end{equation}
so that $S(x) = x + O(x^3)$ from the monicity of $g$ and $h$. Now
$S(x)$ satisfies the differential equation
\begin{equation}
  \label{eq:168}
  (a_6x^6 + a_4x^4 + a_2x^2 + 1){S'}^2 = 1 + a_2'S^2 + a_4'S^4 + a_6'S^6
  \text{,}
\end{equation}
hence we can use a Newton iteration to find a power series
solution. In~\cite[2.4]{bostan+morain+salvy+schost08}, a generic
iteration to solve Eq.~\eqref{eq:168} is used; here we present a more
efficient iteration due to Lercier and
Sirvent~\cite{lercier+sirvent08}.

\pdfmcthree{Modified equation to work when p=3.}
Let 
\begin{equation}
  \label{eq:169}
  G = \frac{1}{1 + a_2x^2 + a_4x^4 + a_6x^6}
  \;\text{,}\qquad
  H = 1 + a_2't^2 + a_4't^4 + a_6't^6
  \text{,}
\end{equation}
Lercier and Sirvent give an algorithm to find a solution in $\K[[x]]$
of any equation of the form
\begin{equation}
  \label{eq:170}
  {S'}^2 = (H\circ S)G
  \text{,}
\end{equation}
with $G\in\K[[x]]$ and $H\in\K[t]$.


\begin{algorithm}
  \caption{\label{alg:le-si-diff} Solve differential equation}
  \begin{algorithmic}[1]
    \REQUIRE $\mu>1$, $\alpha\in\K$, $\beta\in\K^\ast$, $H\in\K[t]$, $G\in\K[[x]]$.
    \ENSURE $S\in\K[[x]]$, solution to ${S'}^2=(H\circ S)G$ modulo $x^{2^\mu}$.
    \STATE let $U \la 1/\beta +O(x)$, $J \la 1/\sqrt{H(\alpha)} + O(x)$, $V \la \sqrt{H(\alpha)} + O(x)$;
    \STATE let $S \la \alpha + \beta x +  \frac{G'(0)H(\alpha) + G(0)H'(\alpha)\beta}{4\beta}x^2+O(x^3)$;
    \FORALL {$d\in\{2, 2^2, \ldots, 2^{\mu-1}\}$}
    \STATE $U \la U(2 - S' U) \mod x^d$;
    \STATE $V \la (V +  (H\circ S) J (2 - VJ))/2 \mod x^d$;
    \STATE $J \la J(2-VJ)) \mod x^d$;
    \STATE \label{alg:le-si-diff:int}$S \la S + V\displaystyle\int\left((H\circ S)G - {S'}^2\right)UJ/2 \mod x^{2d+1}$;
    \ENDFOR
    \STATE output $S$.
  \end{algorithmic}
\end{algorithm}

\begin{theorem}
  Let $\K$ be a field of characteristic $0$ or $p>2^\mu$. Let
  $\alpha,\beta,H,G$ be the inputs to algorithm~\ref{alg:le-si-diff}
  such that $G(0)H(\alpha)=\beta^2$. Then
  Algorithm~\ref{alg:le-si-diff} computes a solution to
  \begin{equation}
    \label{eq:171}
    {S'}^2 = (H\circ S)G
    \text{,}\quad
    S(0) = \alpha
    \text{,}\quad
    S'(0) = \beta
  \end{equation}
  modulo $x^{2^\mu}$ using $O(\Mult(2^{\mu}))$ operations in $\K$.
\end{theorem}
\begin{proof}
  The complete proof is quite long and can be found
  in~\cite{lercier+sirvent08}; here we just give a sketch of it.

  Let $t$ be a solution to Eq.~\eqref{eq:171} modulo $x^{d+1}$ and let
  $h$ be such that 
  \begin{equation}
    \label{eq:175}
    S = t + h \mod x^{2d+1}
    \text{,}
  \end{equation}
  so that $x^{d+1}$ divides $h$.  Then $x^{2d}$ divides ${h'}^2$ and,
  by Eq.~\eqref{eq:171}
  \begin{equation}
    \label{eq:176}
    2t'h' + {t'}^2 = G(x)H(t+h) \mod x^{2d}
    \text{.}
  \end{equation}
  Using the Taylor expansion of $H$ at $t$, we get the linearized
  differential equation
  \begin{equation}
    \label{eq:177}
    2t'h' + {t'}^2 = G(x)H(t) + G(x)H'(t)h
    \mod x^{2d}
  \end{equation}
  with initial condition $h(0)=0$. By Eq.~\eqref{eq:209}, this
  equation has solution
  \begin{equation}
    \label{eq:178}
    h = \frac{1}{J} \int \frac{(G(x)H(t) - {t'}^2)J}{2t'}\diff x
    \text{,}
  \end{equation}
  where $J$ is 
  \begin{equation}
    \label{eq:179}
    J=\exp\left(-\int\frac{G(x)H'(t)}{2t'}\diff x\right)
    \text{.}
  \end{equation}

  The key observation is that, in order to compute the above solution
  to precision $x^{2d+1}$, $J$ must only be known to precision
  $x^d$. But $t$ is a solution of~\eqref{eq:171} modulo $x^{d+1}$, thus 
  \begin{equation}
    \label{eq:172}
    \frac{G(x)H'(t)}{2t'} = \frac{H'(t)t'}{2H(t)} \mod x^d
    \text{,}
  \end{equation}
  hence
  \begin{equation}
    \label{eq:173}
    J = \exp\left(-\frac{1}{2}\log H(t)\right) = \frac{1}{\sqrt{H(t)}}
    \text{.}
  \end{equation}

  Then, at each iteration, the algorithm computes the quantities
  \begin{equation}
    \label{eq:174}
    S,\quad U = 1/S',\quad V = \sqrt{H\circ S},\quad J = 1/V\text{,}
  \end{equation}
  doubling the precision at each iteration. Since the only operations
  are integrals and multiplications of power series, the $i$-th
  iteration costs $O(\Mult(2^i))$ operations in $\K$, thus the last
  iteration dominates the complexity.
\end{proof}


Then, the algorithm to compute the isogeny goes as follows.  The power
series expansion of $S$ is computed to precision $4\ell$, then we set
\begin{equation}
  \label{eq:180}
  S(x) = xT(x^2)
  \text{,}\quad
  R(x) = \frac{1}{T(x)^2}
  \text{,}\quad\text{so that}\quad
  \frac{g(x)}{h(x)} = xR(1/x)
  \text{.}
\end{equation}
Finally, the rational fraction is recovered by rational fraction
reconstruction (see Section~\ref{sec:eucl-algor-rati}); the overall
complexity is dominated by this last step.

\pdfmcthree{Modified algorithm to work when p=3.}
\begin{algorithm}
  \caption{\alg{BMSS}}
  \label{alg:bmss}
  \begin{algorithmic}[1]
    \REQUIRE $\ell>1$, $\ell$-normalized models of $E$ and $E'$ .
    \ENSURE An isogeny $\I:E\ra E'$ of degree $\ell$.
    \STATE Compute $G(x) = 1/(1 + a_2x^2 + a_4x^4 + bx^6) \mod x^{4\ell-1}$;
    \STATE find $S(x)\bmod x^{4\ell-1}$ using Algorithm~\ref{alg:le-si-diff};
    \STATE let $T(x) = \sum_{i=0}^{2\ell-1}s_{2i+1}x^i$;
    \STATE compute $R(x) = 1/T(x)^2 \mod x^{2\ell-1}$;
    \STATE compute $\frac{g(x)}{h(x)}$ by \hyperref[sec:eucl-algor-rati]{rational fraction reconstruction}.
  \end{algorithmic}
\end{algorithm}

\begin{remark}
  \label{rk:bmss}
  Alternatively, if the sum of the abscissas of the kernel
  \begin{equation}
    \label{eq:182}
    p_1 = \sum_{Q\in G^\ast}x(Q)
  \end{equation}
  is known, we can avoid the rational fraction reconstruction.

  The idea is to recover the Newton sums $p_0,\ldots,p_{\ell-1}$ of
  $h$ from $\frac{g(x)}{h(x)}$. From Eq.~\eqref{eq:165} we deduce
  \begin{equation}
    \label{eq:181}
    \begin{aligned}
      &\frac{g(x)}{h(x)} = x + \sum_{i\ge1}\frac{h_i}{x^i},
      \quad\text{where, for any $i\ge1$}\\
      &h_i = (2i+1)p_{i+1} + 2ia_2p_i + (2i-1)a_4p_{i-1} + (2i-2)a_6p_{i-2}
      \text{.}
    \end{aligned}
  \end{equation}
  Thus, knowing $p_0=\ell-1$ and $p_1$ is enough to compute all the
  Newton sums up to $p_{\ell-1}$ using $O(\ell)$ operations (observe,
  in fact, that the equation for $h_1$ has only three non-zero
  summands).

  From the power sums, we can recover $h(x)$ using
  Remark~\ref{rk:newton-sums} in $O(\Mult(\ell))$ operations. Then,
  $g(x)$ is obtained simply multiplying $\frac{g(x)}{h(x)}$ by $h(x)$,
  again in $\Mult(\ell)$ operations.

  Using this approach, we gain a logarithmic factor compared to the
  \hyperref[sec:eucl-algor-rati]{rational fraction reconstruction};
  and the number of coefficients of $S(x)$ to compute goes down to
  $2\ell$. This is similar to the trade-off we had in
  Remark~\ref{rk:shoups-algorithm-1}.

  \pdfmctwo{p1 is not really for free, as I said before. It is just
    absorbed in the rest of the computation.}  The knowledge of $p_1$
  (i.e.\ the coefficient of $x^{\ell-2}$ in $h$) may seem a rather
  bizarre requirement; however, in the Schoof-Elkies-Atkin algorithm
  this information is obtained, together with the normalized model for
  $E'$, from the derivatives of the modular polynomial
  (see~\cite{elkies98,morain95}), and this is why this algorithm has
  been developed.
\end{remark}



\section{Lercier-Sirvent}
\label{sec:lercier-sirvent}
The integral at step~\ref{alg:le-si-diff:int} requires divisions by
all the integers in the interval $[1,\ldots,2^\mu]$, thus, when
$2^{\lceil\log_2(4\ell-1)\rceil}>p$, \titleref{alg:bmss}
encounters a division by $0$. A natural idea is to work in
characteristic $0$ by lifting the curves in the $p$-adics. However,
lifting the Weierstrass models of $E$ and $E'$, there is no guarantee
of obtaining a pair of $\ell$-normalized models, thus
\titleref{alg:bmss} cannot apply.

To circumvent this problem, Lercier and
Sirvent~\cite{lercier+sirvent08} use Elkies' formulas to obtain
normalized models in the $p$-adic, and then apply
\titleref{alg:bmss}. The algorithm is summarized below; it
requires $p\ge5$ and it makes computations in an unramified extension
of degree $d$ of $\Q_p$, denoted by $\Q_q$.

\begin{algorithm*}
  \caption{\alg{Lercier-Sirvent}}
  \label{alg:le-si}
  \begin{algorithmic}[1]
    \REQUIRE $\ell>1$, $E,E'$ $\ell$-isogenous defined over $\F_q$.
    \ENSURE An isogeny $\I:E\ra E'$ of degree $\ell$.

    \STATE \label{alg:le-si:lift1}Take any lift
    $\bar{E}\;:\;y^2=x^3+\bar{a}x+\bar{b}$ of $E$ in $\Q_q$;
    
    \STATE \label{alg:le-si:modpol}Compute a root $\bar{j}'$ of
    $\Modpol_\ell(X,j_{\bar{E}})$ in $\Q_q$ by lifting the solution
    $j_{E'}$;
    
    \STATE \label{alg:le-si:elkies} Compute an $\ell$-normalized model
    $\bar{E}'':y^2=x^3+\bar{a}'x+\bar{b}'$ for $\bar{j}'$;
    
    \STATE \label{alg:le-si:bmss}Apply \titleref{alg:bmss} to $\bar{E}$ and
    $\bar{E}''$ to obtain $\bar{\I}:\bar{E}\ra\bar{E}''$;
    
    \STATE \label{alg:le-si:reduce}Reduce $\bar{E}''$ and $\bar{\I}$
    to $E''$ and $\I$ modulo $p$;
    
    \STATE \label{alg:le-si:isom}Apply an isomorphism $E'\isom E''$ to
    recover $\I:E\ra E'$.
  \end{algorithmic}
\end{algorithm*}

\pdfmcthree{A little detail on the model returned by Elkies' formulas}
Step~\ref{alg:le-si:elkies} uses Elkies' formulas~\cite{elkies98} to
find the $\ell$-normalized model of $\bar{j}'$; these formulas allow
to compute a normalized model of the form $y^2=x^3+ax+b$ from the
knowledge of $\partial\Modpol_\ell/\partial X$ and
$\partial\Modpol_\ell/\partial Y$, and the sum of the abscissas of the
kernel from the knowledge of $\partial^2\Modpol_\ell/\partial X^2$,
$\partial^2\Modpol_\ell/\partial X\partial Y$ and
$\partial^2\Modpol_\ell/\partial Y^2$, using $O(\ell^2)$ operations in
the base field ($\Q_q$, in this case). Analogous formulas exist for
other types of modular polynomials, we address the interested reader
to~\cite{schoof95,morain95,elkies98,lercier-algorithmique}. Notice
that this step fails when $(j_E,j_{E'})$ is a singular point of the
curve $X_0(\ell)$; this condition is very rare for ordinary curves of
large discriminant, as pointed out in~\cite[$\S7$]{schoof95}.

Computations in $\Q_q$ must be approximated to a certain
precision. Lercier and Sirvent show the following fundamental
property.

\begin{proposition}
  \label{th:ls-diffeq}
  If $p\ge5$, on inputs $\ell$, $E$, $E'$, the previous algorithm
  computes the correct answer using at most
  $\left\lceil\log^2\ell/\log p\right\rceil$ $p$-adic digits.
\end{proposition}

Building on this, we now analyze the complexity of the algorithm, for
simplicity we count operations in $\F_q$ rather than in $\F_p$.

\begin{proposition}
  \label{th:lercier-sirvent}
  Algorithm \titleref{alg:le-si} computes an $\ell$-degree isogeny in
  $\tildO(\ell^2)$ operations in $\F_q$, plus $\tildO(\ell^3)$ binary
  operations.
\end{proposition}
\begin{proof}
  We do not take into account the complexity of building the field
  $\Q_q$. Lifting $E$ in $\Q_q$ can be done for free by taking a
  trivial lift. Since the computations in $\Q_q$ are truncated to a
  fixed precision, we only need the coefficients of $\Modpol_\ell\bmod
  p^{\left\lceil\log^2\ell/\log p\right\rceil}$; this can be computed
  using $O(\ell^3\log^3\ell\loglog\ell)$ binary operations and
  $O(\ell^2\log^2\ell)$ bits of space by
  \cite[Algorithm~6.1]{sutherland10:modpol}. The output is a
  polynomial in $\Z_p[X,Y]$ having $O(\ell^2)$ coefficients, this
  requires an equivalent storage of $\tildO(\ell^2)$ elements of
  $\F_p$.

  Then, step~\ref{alg:le-si:modpol} can be done in $\tildO(\ell)$
  operations using Hensel lifting. Steps~\ref{alg:le-si:elkies}
  and~\ref{alg:le-si:bmss} take $O(\ell^2)$ and
  $O(\Mult(\ell)\log\ell)$ operations in $\Q_q$ respectively (slightly
  less if the sum of the abscissas of the kernel of the isogeny is
  computed by Elkies' formulas), this is equivalent to
  $\tildO(\ell^2)$ operations in $\F_q$. The rest of the computation
  is negligible. Thus, the dominating step is~\ref{alg:le-si:elkies}.
\end{proof}

\begin{remark}
  \pdfmcone{More details on how we changed the complexity analysis.}
  Our presentation of the algorithm slightly deviates from the
  original paper~\cite{lercier+sirvent08}. Since we want to compare it
  to Couveignes' algorithm, we assume that the elliptic curve $E'$
  isogenous to $E$ is provided as an input, while
  in~\cite{lercier+sirvent08} it is assumed that only $E$ is known.

  The consequence is that in the original version, before
  step~\ref{alg:le-si:modpol} one has to factor the univariate
  polynomial $\Modpol(X,j_E)$ in $\F_q$ to find an isogenous
  $j$-invariant. Lercier and Sirvent,
  citing~\cite{lidl+niederreiter:2}, estimate this cost to be
  $O(\Mult(\ell)\log q + \Mult(\ell)\log\ell)$ operations in
  $\F_q$. This contribution must be added to the complexity announced
  in Proposition~\ref{th:lercier-sirvent} if one wants to work in the
  original setting.

  Another difference is that we rely on an algorithm to compute the
  modular polynomial $\Modpol_\ell$ in the ring $\Z/m\Z[X,Y]$,
  recently appeared in~\cite{sutherland10:modpol}. This algorithm does
  not improve the binary complexity, however it permits to compute
  $\Modpol_\ell$ in $\Z_p[X,Y]$ truncated to the required precision
  using only $O(\ell^2\log^2\ell)$ bits of memory, instead of
  $\tildO(\ell^3)$, thus improving the algebraic complexity.
\end{remark}


\begin{nota}
  \pdfmcthree{Changed this note again, moved to the bottom of the
    section.}  In the cases $p=2,3$, Elkies' formulas yield a curve
  over $\Q_q$ that reduces badly in $\F_q$. As a consequence, each
  iteration of algorithm~\ref{alg:le-si-diff} introduces some
  additional divisions by $p$, and Proposition~\ref{th:ls-diffeq}
  fails to hold. While it is still possible to apply
  \titleref{alg:le-si} in this case, its complexity gets much worse
  because of the higher $p$-adic precision needed.

  In~\cite{lercier+sirvent08}, Lercier and Sirvent say:
  \begin{quote}
    ``For $p = 2$ (or $p = 3$), Weierstrass models of the form $y^2 + xy
    = x^3 + a_2 x^2 + a_6$ (or $y^2 = x^3 + a_2 x^2 + a_6$) must be
    considered. This yields completely different equations\dots{} [The
    algorithm] can be easily extended to these fields but for the
    sake of simplicity we prefer to omit the details here.''
  \end{quote}
  
  It is true that in the case $p=3$ it is possible to obtain, via
  isomorphism, normalized models for $\bar{E}$ and $\bar{E}''$ of the
  form $y^2 = x^3 + a_2 x^2 + a_6$ that reduce well in $\F_q$. Hence,
  algorithm \ref{alg:le-si-diff} can still be applied to solve the
  differential equation, and the isogeny can be computed using the
  same $p$-adic precision as in Proposition~\ref{th:ls-diffeq}.

  On the other hand, when $p=2$, while it is still possible to obtain
  models of the form $y^2 + xy = x^3 + a_2 x^2 + a_6$ that reduce well
  in $\F_q$, isogenies in such models do not verify an equation as
  simple as Eq.~\eqref{eq:166}. We think that in this case the
  techniques known to solve differential equations are not enough to
  find a solution to this problem.
\end{nota}


% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"american"
% mode:TeX-PDF
% mode:reftex
% TeX-master: "../these"
% End:
%
