Here we recall the basic concepts from abstract algebra that
constitute the background for all the chapters that follow. One
chapter is certainly not enough to present such a vast subject, hence
we just recall the few definitions and properties that will help the
reader understand the results presented in this document. Classic
textbooks on the subject are \cite{lang} for general algebra and
\cite{lidl+niederreiter:2} for finite fields.

\section{Groups, Rings, Modules}
\label{sec:ring-fields}

\subsection{Objects}
\label{sec:ring-fields:objects}

\subsubsection{Groups}

A \index{group}\textbf{group} is a pair $(G,\cdot)$ such that $G$ is a
set and $\cdot:G\times G\ra G$ is an \emph{internal composition law}
satisfying:
\begin{itemize}
\item \index{associativity}\textbf{Associativity}: $(a\cdot b)\cdot c
  = a \cdot (b\cdot c)$ for any $a,b\in G$;
\item There is an element $e\in G$, called the
  \index{identity~element}\textbf{identity}, such that $a\cdot e =
  e\cdot a = a$ for any $a\in G$;
\item For any $a\in G$ there is an
  \index{inverse~element}\textbf{inverse element} $b$ such that
  $a\cdot b = b\cdot a = e$.
\end{itemize}
If $\cdot$ also satisfies $a\cdot b=b\cdot a$
(\index{commutativity}\textbf{commutativity}), the group is said to be
\index{group!abelian}\textbf{abelian}. The group composed of one
single element with the obvious law is called the
\index{group!trivial}\textbf{trivial group}.

A \index{subgroup}\textbf{subgroup} of a group $(G,\cdot)$ is a group
$(H,\circ)$ such that $H\subset G$ and $\circ$ is the restriction of
$\cdot$ to $H$. Any group has two trivial subgroups: the trivial group
and itself. The \index{opposite!group}
\index{group!opposite~group}opposite group of a group $(G,\cdot)$ is
the group $(G,\cdot^\op)$ where $a\cdot^\op b=b\cdot a$ for any
$a,b\in G$.

The \index{center!of~a~group} \index{group!center}\textbf{center} of
$(G,\cdot)$ is the subgroup formed by the elements $a\in G$ such that
$a\cdot b=b\cdot a$ for any $a\in G$. The center is clearly a
commutative group.

Let $A$ be a subset of $G$, the group
\index{group!generator}\index{generator!of~a~group}\textbf{generated}
by $A$, denoted by $\langle A\rangle$, is the smallest subgroup of
$(G,\cdot)$ containing $A$. A finite group generated by a single
element is said to be
\index{cyclic!group}\index{group!cyclic}\textbf{cyclic}; a cyclic
group is necessarily abelian.

Let $(G,\cdot)$ be a group, $(H,\cdot)$ a subgroup and $g\in G$. The
subset $g\cdot H = \{g\cdot h | h \in H \}$ of $G$ is called a
\index{coset!left~coset}\textbf{left coset} of $H$, or simply
\index{coset}coset. A \index{coset!right~coset}\textbf{right coset},
denoted by $H\cdot g$, is a left coset for the opposite group; when
$G$ is abelian the two notions coincide. A subgroup $H$ is called
\index{subgroup!normal}normal if $g\cdot H=H\cdot g$ for any $g\in G$;
note that if $G$ is abelian, any subgroup is normal. Let $H$ be
normal, the cosets of $H$ form a group under the law $(g\cdot
H,g'\cdot H)\mapsto (g\cdot g')\cdot H$, this group is called the
\index{quotient!of~groups}\textbf{quotient} of $G$ by $H$ and is
denoted by $G/H$.

Let $S$ be a set and let $G$ be a group. A
\index{group~action!left~group~action}
\index{group~action}\textbf{(left) group action} of $G$ over $S$ is a
law $.:G\times S\ra S$ such that for any $g,g'\in G$ and $x\in S$,
\begin{itemize}
\item $g'.(g.x) = (g'\cdot g). x$,
\item $e. x = x$.
\end{itemize}
A \index{group~action!right~group~action}\textbf{right group action}
is a left group action for the opposite group.


\subsubsection{Rings, Fields}

A \index{ring}\textbf{ring} is a tuple $(R,+,\cdot)$ such that $(R,+)$
is an abelian group and $\cdot:R\times R\ra R$ is an internal
composition law satisfying associativity, existence of the identity
and \index{distributivity}\textbf{distributivity} over $+$
\[a \cdot (b + c) = (a\cdot b) + (a\cdot c) \quad\text{for any
  $a,b,c\in R$.}\] When $\cdot$ satisfies commutativity, the ring is
said to be \index{ring!commutative}\textbf{commutative}.  The law $+$
is called \emph{addition}, $\cdot$ is called \emph{multiplication},
the identity for $+$ is denoted by $0$ and the identity for $\cdot$ by
$1$.  A commutative ring such that $1\ne 0$ and where $\cdot$ also
satisfies the existence of the inverse, is called a
\index{field}\textbf{field}.

The group $(R,+)$ is called the \index{additive~group}\textbf{additive
  group} of $R$. Let $R^\ast$ be the subset consisting in the elements
of $R$ that have both a left and a right inverse for $\cdot$, the
group $(R^\ast,\cdot)$ is called the
\index{multiplicative~group}\textbf{multiplicative group} or the
\index{group!of~units}\textbf{group of units} of $R$.

A \index{subring}\textbf{subring} of a ring $(R,+,\cdot)$ is a ring
$(S,\ast,\circ)$ such that $(S,\ast)$ is a subgroup of $(R,+)$ and
$\circ$ is the restriction of $\cdot$ to $S$.  The
\index{opposite!ring}\index{ring!opposite~ring}\textbf{opposite ring}
of a ring $(R,+,\cdot)$ is the ring $(R,+,\cdot^\op)$
where $a\cdot^\op b=b\cdot a$ for any $a,b\in R$.

The simplest example of ring is $\Z$, the set of integers; the
rational numbers $\Q$ are an example of field, it is the
\emph{smallest} field containing $\Z$ as a subring. The
\index{ring!trivial}\textbf{trivial ring} is the ring composed of one
unique element $r=0=1$ with the evident laws; note that by definition
this is not a field.

\subsubsection{Modules, ideals, vector spaces}

Given a ring $(R,+,\cdot)$ a \index{module!left~module}\textbf{left
  module}, or simply \textbf{module}, over $R$ is a tuple $(M, +_M,
\cdot_M)$ such that $(M,+_M)$ is an abelian group and $\cdot_M:R\times
M\ra M$ is an \emph{external law} such that for any $r,r'\in R$ and
$m,m'\in R$
\begin{itemize}
\item $(r + r')\cdot_M m = (r \cdot_M m) +_M (r'\cdot_M m)$,
\item $r\cdot_M(m +_M m') = (r\cdot_M m) +_M (r'\cdot_M m)$,
\item $r'\cdot_M(r\cdot_M m ) = (r'r)\cdot_M m$,
\item $1\cdot_M m = m$.
\end{itemize}
The law $+_M$ is called \emph{addition}, its identity is denoted by
$0$; the law $\cdot_M$ is called
\index{multiplication!scalar}\index{scalar~multiplication}\textbf{scalar}
or
\index{mutliplication!external}\index{external~multiplication}\textbf{external}
multiplication. 

A \index{module!right~module}\textbf{right module} is a left module
for the opposite ring $R^\op$, a
\index{module!two-sided}\textbf{two-sided module} also called
\index{bimodule}\textbf{bimodule} is an object that is both a left and
a right module. When $R$ is commutative, the three notions coincide
and we simply speak of a \index{module}\textbf{module}.  $R$-module is
another way of saying ``module over $R$''. When $\K$ is a field, a
$\K$-module is called a \index{vector~space}\textbf{$\K$-vector
  space}. When $R$ is commutative, a ring $S$ that is also an
$R$-module is called an \index{algebra}\textbf{$R$-algebra}.

A \index{module!submodule}\index{submodule!left~submodule}left
(\index{submoudle!right~submodule}right,
\index{submodule!two-sided}two-sided) \textbf{submodule} of a left
(right, two-sided) $R$-module $(M,+,\cdot)$ is a left (right, two-sided)
$R$-module $(N,\ast,\circ)$ such that $(N,\ast)$ is a subgroup of
$(M,+)$ and $\circ$ is the restriction of $\cdot$ to $R\times N$.

Let $A$ be a subset of $M$, the module
\index{group!generator}\index{generator!of~a~group}\textbf{generated}
by $A$, denoted by $\langle A\rangle$ or $(A)$, is the smallest
submodule of $(M,+,\cdot)$ containing $A$.

The module containing one unique element with the evident laws is
called the \index{module!zero~module}\textbf{zero module}; any
$R$-module contains a submodule that is isomorphic to the zero module.
Any abelian group $(G,+)$ can be given a $\Z$-module structure by the
law
\[n\cdot g = \underbrace{g + \cdots + g}_{n\text{ times}} \text{.}\]
The \index{order!of~an~element}\textbf{order} of an element $g$ is the
smallest strictly positive integer $n$ such that $n\cdot g=e$; if no
such $n$ exists, $g$ is said to have
\index{order!infinite}\textbf{infinite order}. When a group is finite,
we also call \index{order!of~a~group}\textbf{order} its cardinality;
the order of any element divides the order of the group.

In particular any ring is a $\Z$-algebra. The
\index{characteristic}\textbf{characteristic} of a ring $(R,+,\cdot)$
is the order of $1$ in $(R,+)$. By convention we say that the
characteristic is $0$ if $1$ has infinite order. The characteristic of
a field can only be $0$ or a prime number.

Any ring $R$ is trivially a two-sided module over itself; a
\index{ideal!left~ideal} (\index{ideal!right~ideal}right,
\index{ideal!two-sided}two-sided) \textbf{ideal} of a ring $R$ is a
submodule of the left (right, two-sided) $R$-module $R$.  When $R$ is
commutative one simply speaks of an \index{ideal}ideal.  

Any ring contains at least two submodules: the zero module and itself;
these are called the \index{ideal!trivial}\textbf{trivial ideals}. The
only non-trivial ideals of $\Z$ are the $n\Z$ for any $n\ne0,1$. A
field has no non-trivial ideals.

The \index{direct~sum}\textbf{direct sum} $M\oplus N$ of two
$R$-modules $(M,+_M,\cdot_M)$ and $(N,+_N,\cdot_N)$ is the module
$(M\times N,+,\cdot)$ where the laws $+$ and $\cdot$ are defined
component-wise. This generalizes to sums of an arbitrary number of
modules: let $(M_i)_{i\in I}$ be a sequence of $R$-modules, the direct
sum $\bigoplus_{i\in I}M_i$ is the $R$-module whose elements are the
sequences $(m_1,m_2,\ldots)$ where $m_i\in M_i$ and $m_i=0$ for all
but a finite number of them; the laws are defined component-wise.
Although less commonly used, there also exists a notion of
\index{direct~product}\textbf{direct product}: given $(M_i)_{i\in I}$,
the direct product $\prod_{i\in I}M_i$ is the $R$-module whose
elements are the sequences $(m_1,m_2,\ldots)$ where $m_i\in M_i$ with
the laws defined component-wise. Clearly, the two definition coincide
when $I$ is a finite set.

When $R$ is seen as an $R$-module over itself, we denote by $R^n$ the
direct sum $\bigoplus_{0<i\le n}R$ and by $R^\infty$ the direct sum
$\bigoplus_{i>0}R$. An $R$-module that is isomorphic to the direct sum
$\bigoplus_{I}R$ for some $I$ is called a
\index{module!free}\textbf{free module}. A \index{basis}\textbf{basis}
of a module $M$ is a family $(m_i)_{i\in I}$ of elements of $M$ such
that any $m\in M$ can be written as 
\begin{equation}
  \label{eq:module-basis}
  m = \sum_{i\in I} r_i\circ m_i
  \quad\text{with $r_i\in R$}
\end{equation}
in an unique way. Clearly, if we denote by $e_i$ the element of
$\bigoplus_IR$ that has $1$ in the $i$-th position and $0$ elsewhere,
the family $(e_i)_{i\in I}$ forms a basis; hence, any free module has
a basis and, conversely, any module that has a basis is free. One
important statement about bases of modules is the following.

\begin{proposition}
  \label{th:invariant-basis}
  Any two bases for a free module $M$ over a commutative ring $R$ have
  the same cardinality.
\end{proposition}

For this reason, when $M$ is a free module over a commutative ring $R$
we call \index{dimension} \index{dimension!of~a~module}
\index{module!free!dimension~of} \index{dimension!of~a~bector~space}
\index{vector~space!dimension~of}\textbf{dimension} the cardinality of
any of its bases. It is a well known result in linear algebra that any
vector space has a basis, hence any $\K$-vector space is free as a
$\K$-module.

Given a module $M$ and a submodule $N$, the quotient group $M/N$ can
be given a module structure by the law $r\cdot(m+N)=(r\cdot m)+N$, it
is then called the \index{quotient!of~modules}\textbf{quotient
  module}. When $R$ is a ring and $I$ a module, the quotient $R/I$ can
also be given a ring structure by the law $(r+I)\cdot(r'+I)=(r\cdot
r')+I$, it is then called the \index{quotient!of~ring}\textbf{quotient
  ring}.

In what follows we will follow the common practice and abuse the
notation in several ways:
\begin{itemize}
\item When different groups (rings, modules) are involved in a
  statement, we will often use the same symbols for all the group
  (ring, module) laws; the context will always make clear which group
  law is involved.
\item We will often use sentences like ``Let $G$ be a group (ring,
  module)'' without explicitly giving the symbols for the laws: the
  symbols $+$ and $\cdot$ are then implied. A
  \index{additive~notation}
  \index{group!written~additively}\textbf{group written additively}
  will be a group whose law is denoted by $+$; a
  \index{multiplicative~notation}
  \index{group!written~multiplicatively}\textbf{group written
    multiplicatively} will be a group whose law is denoted by $\cdot$.
\item Recall that any abelian group is a $\Z$-module. For a $g\in G$,
  the external multiplication by an element $n\in\Z$ will be written
  $n\cdot g$ or $ng$ in additive notation, $g^n$ in multiplicative
  notation.
\item The operator $\cdot$ will always have higher precedence than
  $+$, and it will often be omitted. Thus $ab+cd$ is just a compact
  notation for $(a\cdot b) + (c\cdot b)$.
\item To avoid ambiguities, in particular when the $\cdot$ operator is
  omitted, the elements of the opposite group/ring will be denoted by
  $a^\op$ for any $a\in G$. Thus $a^\op b^\op=(ba)^\op$.
\end{itemize}


\subsection{Arrows}
\label{sec:ring-fields:arrows}

Given two groups $G$ and $G'$, a
\index{morphism!of~groups}\textbf{morphism} from $G$ to $G'$,
sometimes also called a
\index{homomorphism|see{morphism}}\textbf{group homomorphism}, is a
mapping $f:G\ra G'$ that \emph{commutes} with the group law and
\emph{preserves} the identity, that is
\begin{itemize}
\item $f(a\cdot b) = f(a) \cdot f(b)$,
\item $f(e) = e$.
\end{itemize}

A \index{morphism!of~rings}\textbf{morphism of rings} is a group
morphism that commutes with multiplication and preserves $1$, a
\index{morphism!of~modules}\textbf{morphism of modules} is a group
morphism that commutes with the external multiplication.

The \index{kernel}\textbf{kernel} of a group morphism $f:G\ra G'$,
denoted by $\ker f$, is the subgroup of $G$ consisting of the elements
such that $f(g)=e$. The kernel of a ring (module) morphism is the
kernel of the underlying group morphism.

The \index{image}\textbf{image} of a group morphism $f:G\ra G'$,
denoted by $\im f$, is the subgroup of $G'$ consisting of the elements
$g'$ such that $f(g)=g'$ for some $g\in G$. The image of a ring
(module) morphism is the image of the underlying group morphism.

A morphism $f:A\ra B$ is said to be
\index{morphism!injective}\textbf{injective} is its kernel is the zero
subgroup of $A$, \index{morhpism!surjective}\textbf{surjective} if its
image is the whole $B$, \index{morphism!bijective}\textbf{bijective}
if it is both. A bijective morphism is also called an
\index{isomorphism}\textbf{isomorphism}, two groups (rings, modules)
such that there is an isomorphism between them are said to be
\index{isomorphic}\textbf{isomorphic}, if $A$ and $B$ are isomorphic
we write $A\isom B$. A morphism $f:A\ra A$ is also called an
\index{endomorphism}\textbf{endomorphism}, a bijective endomorphism is
called an
\index{automorphism}\textbf{automorphism}. 

Sometimes, in the special case of $R$-module morphisms, we say
\index{linear!map}\textbf{$R$-linear map} instead of morphism, and
\index{linear!operator}\textbf{$R$-linear operator} on $M$ instead of
endomorphism of $M$. Linear maps $f:M\ra R$ are also called
\index{form!linear|see{linear}} \index{linear!form}\textbf{$R$-linear
  forms}.

\begin{proposition}
  \label{th:first-isomorphism}
  The kernel of a group morphism $f:A\ra B$ is a normal subgroup of
  $A$ and the image is a subgroup of $B$.  If $f$ is a ring morphism,
  $\ker f$ is an ideal and $\im f$ a subring. If $f$ is a module
  morphism, $\ker f$ and $\im f$ are both submodules.
  
  In each of these cases $\im f$ is isomorphic to $A/\ker f$ as a
  group/ring/module.
\end{proposition}

\index{morphism!zero~morphism} \textbf{Zero morphisms} are those
morphisms $f:A\ra B$ such that $\ker f = A$.  An easy consequence of
the proposition is that, since a field has no non-trivial ideals, any
non-zero morphism of fields is injective; for this reason a morphism
from a field $\K$ to a field $\LK$ is also called an
\index{embedding}\textbf{embedding} of $\K$ into $\LK$.

The set of group/ring/module morphisms from $A$ to $B$ is denoted by
$\hom(A,B)$. If $A$ and $B$ are (abelian) groups, then $\hom (A,B)$ is
a (abelian) group by the law $(f\cdot g)(a) = f(a)\cdot g(a)$. If $A$
and $B$ are $R$-modules, the set of morphisms of modules may also be
written $\hom_R(A,B)$ if the ring is not clear from the context; if
$A$ and $B$ are right modules, the set of morphisms is conveniently
written as $\hom_{R^\op}(A,B)$. In general $\hom_R(A,B)$ and
$\hom_{R^\op}(A,B)$ are only abelian groups, but when $R$ is
commutative they are equal and they also have an $R$-module structure
by the law $(a\cdot f)(b) = a\cdot f(b)$.

If $A$ is a group/ring/module, $\hom(A,A)$ has a ring structure by the
law $f\cdot g=f\circ g$, where $\circ$ is composition of functions. It
is called the \index{ring!of~endomorphisms}
\index{endomorphism~ring}endomorphism ring of $A$ and is denoted by
$\End(A)$. When $A$ is a module over a commutative ring and we want to
stress the fact that $\End(A)$ is an $R$-algebra, we write
$\End_R(A)$. We denote by $\Aut(A)$ the multiplicative subgroup of
$\End(A)$, it is the group of automorphisms of $A$.

Let $M$ be a left $R$-module, then $\hom_R(M,R)$ is a right $R$-module
by the law $(a^\op \cdot f)(b) = f(b)\cdot a$; similarly, if $M$ is a
right $R$-module, $\hom_{R^\op}(M,R)$ is a left $R$-module (a right
$R^\op$-module). Both are called the
\index{module!dual~module}\index{dual!of~a~module}\textbf{dual module}
of $M$ and are denoted by $\dual{M}$.

A convenient way of expressing properties of morphisms is to draw
\index{diagram}\textbf{diagrams} where objects (groups, rings, etc.)
are connected by arrows representing morphism. A diagram
\[\xymatrix{A\ar[r]^f\ar[dr]_h & B \ar[d]^g\\&C}\]
is said to be \index{diagram!commutative}\textbf{commutative} if
$g\circ f = h$. In general, we call \index{sequence}\textbf{sequence}
any sequence of consecutive arrows in a diagram. A diagram is
commutative if, whenever two sequences
\[\xymatrix{A\ar[r]^{f_1} & \cdots \ar[r]^{f_n} & B}\]
and
\[\xymatrix{A\ar[r]^{g_1} & \cdots \ar[r]^{g_n} & B}\]
connect the same two objects, $f_1\circ\cdots\circ
f_n=g_1\circ\cdots\circ g_m$.  A sequence
\[\xymatrix{\cdots \ar[r] & A_{i-1}\ar[r]^{f_{i-1}} & A_i \ar[r]^{f_i}
  & A_{i+1} \ar[r] & \cdots}\]
is said to be \index{sequence!exact}
\index{exact~sequence}\textbf{exact} if $\ker f_i = \im f_{i-1}$ for
any $i$.


\section{Linear algebra}
\label{sec:linear-algebra}

We apply concepts from classical linear algebra to free modules over
rings; we assume that the reader is familiar with matrices and the
related language. In this section $R$ will be a non necessarily
commutative ring and module will mean $R$-module.

\subsection{Bra-ket notation}
\label{sec:linear-algebra:bra-ket}

It will be convenient to (ab)use Dirac's
\index{bra-ket~notation}bra-ket notation to represent elements of
modules. If $(M,+,\cdot)$ is a left $R$-module and $x\in (M,+)$ is an
element of its underlying group, by $\ket{x}_R$ we mean the element
obtained by lifting $x$ in $(M,+,\cdot)$. We call $\ket{x}$ a
\index{ket}\textbf{ket} and read it as ``ket x''.

The external multiplication by an element $a\in R$ will be written
$a\ket{x}_R$; if $f:M\ra N$ is a left module morphism, we write
$f\ket{x}_R$ for $f(\ket{x}_R)$. By a slight abuse of notation we may
write $\ket{a x}_R$ and $\ket{f(x)}_R$ for $a\ket{x}_R$ and
$f\ket{x}_R$ respectively. When $R$ is clear from the context, a ket
can be simply written as $\ket{x}$.

In a symmetric way, elements of right $R$-modules will be written
${}_R\bra{x}$, which we call a \index{bra}\textbf{bra} and read as
``bra x''. External multiplication will be written as ${}_R\bra{x}a$
and application of a right module morphism as ${}_R\bra{x}f$.

Let $M$ be a right module and $N$ a left module. A
\index{form!bilinear|see{bilinear~form}}
\index{bilinear~form}\textbf{bilinear form} on $M\times N$ is a map
$f:M\times N\ra R$ such that for any $x\in M$, the map
\[\ket{y}\mapsto f(x, y)\]
is a left module morphism, and for any $y\in N$, the map
\[\bra{x}\mapsto f(x, y)\]
is a right module morphism. If $f$ is a bilinear form, we write
$\braket{x}{y}_f$ for $f(x,y)$, or simply $\braket{x}{y}$
when $f$ is clear from the context. Note that textbooks usually define
bilinear forms only when $R$ is commutative, in our more general
setting some common properties of bilinear forms fail to hold,
for example $\braket{xa}{y}\ne\braket{x}{ay}$.

Any bilinear form $f$ gives rise to a morphism $ \phi_f : M \ra
\dual{N}$ of right modules where $\bra{x}\phi_f$ is the linear form $y
\mapsto \braket{x}{y}$. Similarly, $f$ gives rise to a morphism
$\phi^f:N\ra\dual{M}$ of left modules. The maps $f\mapsto\phi_f$,
$f\mapsto\phi^f$ and their obvious inverses induce group isomorphisms
between $\hom(M,\dual{N})$, $\hom(N,\dual{M})$ and the group of
bilinear forms on $M\times N$.

A bilinear form $f$ is said to be
\index{bilinear~form!degenerate}\textbf{non-degenerate} if
$\braket{x}{y}=0$ implies $x=0$ and $y=0$. It is said to
be \index{bilinear~form!singular}\textbf{non-singular} if $\phi_f$ and
$\phi^f$ are module isomorphisms; a non-singular form is necessarily
non-degenerate.


\subsection{Matrices}
\label{sec:linear-algebra:matrices}
Let $M=M_1\oplus\cdots\oplus M_n$ and $N=N_1\oplus\cdots\oplus N_m$,
let $\iota_i$ be the injections $M_i\ra M$ and let $\pi_j$ be the
projections $N\ra N_i$, then a linear map $f:M\ra N$ is uniquely
determined by the maps $\pi_j\circ f\circ\iota_i$. If we consider
$m\times n$ matrices whose $(j,i)$-th coefficient is in
$\hom(M_i,N_j)$, then we verify that there is a group isomorphism
between $\hom(M,N)$ and this group of matrices. Furthermore, let
$f:M\ra N$ and $g:N\ra O$ and let $M_f$ and $M_g$ be the matrices that
are associated respectively, then the matrix associated to $g\circ f$
is $M_gM_f$, where the product of two entries is defined as
composition of morphisms. This induces a ring isomorphism between
$\End(M)$ and the ring of square matrices with entries in
$\hom(M_i,M_j)$.

Consider $R$ as an $R$-module over itself, a linear map from $R$ to
itself is uniquely determined by the image of $1$, hence $\End(R)\isom
R^\op$. As a consequence, there is a group isomorphism
$\hom(R^n,R^m)\isom\Mat_{m\times n}(R^\op)$ and matrix multiplication
is equivalent to composition as above.

Hence, when $M$ is a free module over a commutative ring $R$, by
proposition \ref{th:invariant-basis} any basis has the same
cardinality. Assume $M\isom R^n$, then for a fixed basis $\basis{B}$
of $M$ we have an isomorphism of $R$-algebras
$\End_R(M)\isom\Mat_n(R)$; in particular $\Aut(M)\isom\GL_n(R)$ as
groups.

We denote by $M_{\basis{B}}(f)$ the matrix associated to
$f\in\End_R(M)$ with respect to the basis $\basis{B}$.  If
$\basis{B'}$ is another basis, there is an invertible matrix $B$ such
that $A\mapsto B^{-1}AB$ is the automorphism of $\Mat_n(R)$ that sends
$M_{\basis{B}}(f)$ over $M_{\basis{B'}}(f)$. Hence, any property of
matrices that is invariant by similarity, can be defined for linear
operators. We define the \index{trace!of~an~operator}
\index{trace}{trace} of a linear operator as $\Tr f = \Tr M(f)$, and
its \index{determinant}\textbf{determinant} as $\det f = \det M(f)$.


\subsection{Duality}
\label{sec:linear-algebra:duality}
In this section we fix a non-singular bilinear form $f$ on $M\times
N$. Let $g\in\End(M)$, then the map
\[(x,y) \mapsto \braket{g(x)}{y}_f\] is a bilinear
form. On the other hand, let $h$ be a bilinear form on $M\times N$,
for any $x\in M$ the map $h_x : \ket{y} \mapsto \braket{x}{y}_h$
is a linear form on $N$, thus $h_x\in\dual{N}$. From the
non-singularity of $f$ we deduce that there is an unique element
$x'\in M$ such that $\braket{x'}{y}_f=\braket{x}{y}_h$ and it is
clear that the map $\bra{x}\mapsto \bra{x'}$ is an endomorphism of
$M$. It is evident that the two maps are each other's inverse, thus we
have a group isomorphism between $\End(M)$ and the group of bilinear
forms. An analogous argument shows that $\End(N)$ is isomorphic to the
group of bilinear forms and ultimately $\End(M)\isom\End(N)$.

A consequence of this is that for any linear operator $g\in\End(M)$
there is an operator $\dual{g}\in\End(N)$ such that
\[\braket{g(x)}{y}_f = \braket{x}{\dual{g}(y)}_f\]
for any $x\in M$ and $y\in N$. We define similarly $\dual{h}$ when
$h\in\End(N)$, obviously $\dual{(\dual{g})} = g$. The operator
$\dual{g}$ is called the \index{dual!operator}\textbf{dual} of $g$
with respect to $f$. In general, whenever it is clear from the context
that $g$ belongs to $\End(M)$ (or to $\End(N)$), we simply write
\[\braketop{x}{g}{y} = \braket{g(x)}{y} = \braket{x}{\dual{g}(y)}\text{.}\]

More generally, Let $f:M\times M'\ra R$ and $g:N'\times N\ra R$ be two
non-singular bilinear forms, by the same technique as above we can
show that there is a group isomorphism between $\hom_R(N,M')$,
$\hom(M,N')$ and the bilinear forms on $M\times N$. Then For any
$h:N\ra M'$ there is an unique $\dual{h}:M\ra N'$ such that
\[\braket{x}{h(y)}_f = \braket{\dual{h}(x)}{y}_g =
\braketop{x}{h}{y}\text{.}\]
We also call $\dual{h}$ the \textbf{dual} of $h$.

The canonical example of non-singular bilinear forms is obtained by
considering the family of forms on $\dual{M}\times M$ defined by
\[\braket{\ell}{x} = \ell(x) \text{.}\]
For any $f:M\ra N$, we define the dual map
$\dual{f}:\dual{N}\ra\dual{M}$ as the map that sends a form
$\ell\in\dual{N}$ over the form $\ell\circ f$ in $\dual{M}$; it is
easy to verify that
\[\braketop{\ell}{f}{x} =  \braket{\ell}{f(x)} = \braket{\dual{f}(\ell)}{x}
= \ell(f(x))\text{.}\]

In the special case where $M$ and $N$ are free modules, for any fixed
finite bases of $M$ and $N$, kets are isomorphic to column vectors,
bras to row vectors, and the bilinear form $\braket{\ell}{x}=\ell(x)$
is given by the inner product
\begin{equation*}
  \left\langle\begin{matrix}
      \ell_1 &\cdots & \ell_n
    \end{matrix}\right\rvert
  \left\lvert\begin{matrix}
    x_1\\
    \vdots\\
    x_n
  \end{matrix}\right\rangle
  =
  \sum_i x_i\ell_i
\end{equation*}
(notice how the product is swapped, this is because $\End(R)\isom
R^\op$).  Now a linear map $f:M\ra N$ is just a matrix with entries in
$R^\op$, the application $f\ket{x}$ is just matrix-vector
multiplication, while $\bra{\ell}\dual{f}$ is vector-matrix
multiplication by the same matrix. This justifies the notation
$\braketop{\ell}{A}{x}$ where $A$ is the matrix associated to $f$.


\section{Basic Galois theory}
\label{sec:basic-galois-theory}

We assume the reader is familiar with polynomials. All the rings in
this section will be commutative.

\subsection{Algebraic extensions}
\label{sec:basic-galois-theory:algebraic-extensions}
Given a commutative ring $R$ and a subring $S$, we say that $R$ is a
\index{extension!of~rings} \index{ring!extension}\textbf{ring
  extension} of $S$ and we write $R/S$ (don't confuse this with a
quotient ring). 

If $x$ is an element of $R$, by $S[x]$ we denote the smallest subring
of $R$ containing $S$ and $x$ and we call it the ring
\index{generator!of~a~field}
\index{generator!of~a~ring}\textbf{generated by $x$ over $S$}. More
generally we write $S[x_1,x_2,\ldots]$ for the smallest subring
containing $S$ and all the $x_i$'s and call it the ring \textbf{generated by
the family $(x_i)_{i\in I}$ over $S$}.

When $R$ and $S$ are fields, $R/S$ is called a
\index{extension!of~fields} \index{field!extension}\textbf{field
  extension}. An element $x\in R$ is said to be
\index{algebraic!element}\textbf{algebraic over} $S$ if there is a
non-zero polynomial $P$ with coefficients in $S$ such that
$P(x)=0$. If an element is not algebraic, it is said to be
\index{transcendental!element}transcendental. A field extension $R/S$
is said to be \index{algebraic!extension}\textbf{algebraic} if any
$x\in R$ is algebraic over $S$,
\index{transcendental!extension}\textbf{transcendental} otherwise.

$\C/\R$ and $\C/\Q$ are examples of field extensions, the first is
algebraic, the second is transcendental. A classic example of
extension of a ring $R$ is the ring of polynomials in the variable $X$
with coefficients in a ring $R$; it is usually denoted by $R[X]$
without further precision on a ring containing it. If $\K$ is a field,
$\K[X]$ is a transcendental extension.

IF $\LK/\K$ is a field extension, $\LK$ has a natural structure of
vector space over $\K$, hence it has a dimension as $\K$-vector space
that we denote by $[\LK:\K]$ and we call the
\index{field!extension!dimension}
\index{dimension!of~a~field~extension}\textbf{dimension} of the field
extension. A field extension is said to be
\index{field!extension!finite}\textbf{finite} if its dimension is
finite, \index{field!extension!infinite}\textbf{infinite} otherwise. A
finite extension $\LK/\K$ cannot be transcendental, otherwise one
could exhibit an infinite basis for the $\K$-vector space $\LK$;
hence, any finite extension is algebraic.

Let $\LK/\K$ and $\K/k$ be field extensions, if $(x_i)_{i\in I}$ is a
basis for $\L$ over $\K$ and $(y_j)_{j\in J}$ is a basis for $\K$ over
$k$, then $(x_iy_j)_{(i,j)\in I\times J}$ is a basis for $\LK$ over $k$ and
\[[\LK/k] = [\LK/\K][\K:k] \text{.}\] A sequence of field extensions
$\K_1\subset\K_2\subset\cdots\subset\K_n$ is called a
\index{field!extension!tower} \index{tower~of~fields}\textbf{tower} of
fields.

If $x$ is algebraic over $\K$, then there is a smallest degree monic
irreducible polynomial $P$ such that $P(x)=0$. Such polynomial is
called the \index{minimal~polynomial}\textbf{minimal polynomial} of
$x$ over $\K$.  Let $\LK/\K$ be a field extension and let $x\in\LK$,
by $\K(x)$ we denote the smallest subfield of $\LK$ containing $\K$
and $x$.

\begin{proposition}
  Let $x$ be algebraic over $\K$, let $P$ be its minimal polynomial
  and let $(P)$ be the ideal of the polynomial ring $\K[X]$ generated
  by $P$. Then $\K[x]=\K(x)\isom K[X]/(P)$ and $[\K[x]:\K] = \deg P$.
\end{proposition}

A field $\K$ is called
\index{algebraically~closed}\index{field!algebraically~closed}
\textbf{algebraically closed} if every polynomial in $\K[X]$ has a
root in $\K$.

\begin{theorem}
  Let $\K$ be a field, there exist an algebraically closed field
  containing $\K$ as a subfield.
\end{theorem}

An algebraic extension of $\K$ that is algebraically closed is called
an \index{algebraic~closure}\index{field!algebraic~closure}
\textbf{algebraic closure} of $\K$. The algebraic closure is unique up
to isomorphism, we will denote it by $\clot{\K}$.


\subsection{Galois extensions}
\label{sec:basic-galois-theory:galois-extensions}
Whenever $P$ is an irreducible polynomial in $\K[X]$, the quotient
ring $\K[X]/(P)$ is a finite field extension of $\K$; it may also be
written $\K[X]/P(X)$. Up to isomorphism, this is the smallest
extension of $\K$ where $P$ has a root. It is also the smallest
extension where $P$ factors completely into linear terms and is called
the \index{splitting~field}\textbf{splitting field} of $P$ over
$\K$. 

More generally a \textbf{splitting field} of a family of generic
polynomials $(Q_i)_{i\in I}$ in $\K[X]$ is defined as an extension of
$\K$ where all the $Q_i$ factor completely into linear terms and such
that $\LK$ is generated over $\K$ by the roots of the $Q_i$. An
algebraic field extension $\LK/\K$ such that $\LK$ is the splitting
field of a family of polynomials in $\K[X]$ is called a
\index{field!extension!normal} \index{normal~extension} \textbf{normal
  extension}.

Let $\LK/\K$ be an algebraic field extension, an element $x\in\LK$ is
said to be \index{separable!element} \textbf{separable} over $\K$ if
its minimal polynomial over $\K$ has no multiple roots in $\LK$.
$\LK/\K$ is said to be \index{field!extension!separable}
\index{separable!extension} \textbf{separable} if every $x\in\LK$ is
separable over $\K$. An algebraic field extension is said to be a
\index{field!extension!Galois} \index{Galois~extension} \textbf{Galois
  extension} if it is both separable and normal.

\begin{theorem}
  Let $\LK/\K$ be a finite Galois extension, then there exists an
  element $x\in\LK$, called a
  \index{primitive!element}\textbf{primitive element}, such that
  $\LK\isom\K[x]$.
\end{theorem}

Let $\LK/\K$ be a Galois extension, the group of automorphisms of
$\LK$ that fix $\K$ is called the \index{Galois~group}\textbf{Galois
  group} of $\LK/\K$ and is denoted by $\Gal(\LK/\K)$.  Let $G$ be a
group of automorphisms of a field $\K$, by $\K^G$ we denote the
subfield of $\K$ consisting in the elements such that $\sigma(x)=x$
for any $\sigma\in G$. Obviously, $\K=\LK^{\Gal(\LK/\K)}$.

\begin{theorem}
  Let $\LK/\K$ be a finite Galois extension. Let $H$ be a subgroup of
  $G=\Gal(\LK/\K)$, the map $H\mapsto \LK^H$ is a bijection between
  the subgroups of $G$ and the subfields of $\LK$ containing $k$. The
  extension $\LK^H/\K$ is Galois if and only if $H$ is a normal
  subgroup of $G$; in this case its Galois group is isomorphic to
  $G/H$.
\end{theorem}

Let $\LK/\K$ be a Galois extension and let $x\in\LK$. The elements
$\sigma(x)$ for $\sigma\in\Gal(\LK/\K)$ are called the
\index{conjugate~element}\textbf{conjugates} of $x$ under the action
of $\Gal(\LK/\K)$; they correspond to the roots of the minimal
polynomial of $x$ over $\K$.

Let $\K$ be a field, an element $x\in \K$ such that $x^n=1$ is called
an $n$-th \index{root~of~unity}\textbf{root of unity}. If the
characteristic of $\K$ does not divide $n$, the polynomial $X^n-1$ has
$n$ distinct roots in $\clot{\K}$ and they form a multiplicative
group, denoted by $\mu_n$. $\mu_n$ is a cyclic group, its generators
are called the \index{primitive!root~of~unity}
\index{root~of~unity!primitive} \textbf{primitive} roots of unity.  If
$\K$ has characteristic $p>0$, then $X^{p^m}-1$ has only one root,
namely $1$, thus $\mu_{p^m}$ is the trivial group. 

The \index{Euler~function}\textbf{Euler function} $\euler:\N\ra\N$ is
defined as
\begin{align*}
  \euler(1) &= 1 &\text{,}\\
  \euler(p^r) &= p^{r-1}(p-1) &\text{for $p$ prime, $r\ge1$,}\\
  \euler(nm) &= \euler(n)\euler(nm) &\text{when $\gcd(n,m)=1$.}
\end{align*}
The Euler function counts the number of generators of the cyclic group
with $n$ elements, thus, when the characteristic of the field does not
divide $n$, the number of primitive roots of unity is equal to $\euler(n)$.

\begin{theorem}
  Let $x$ be a primitive $n$-th root of unity in an algebraic closure
  of $\Q$, then
  \[[\Q(x):\Q]=\euler(n)\text{.}\]
\end{theorem}

If $x$ is an $n$-th root of unity, its minimal polynomial over $\Q$ is
called the $n$-th \index{cyclotomic~polynomial}\textbf{cyclotomic
  polynomial} and is denoted by $\Cyclo_n$; it is a monic polynomial
with coefficients in $\Z$. $\Cyclo_n$ is an irreducible factor of
$X^n-1$ over $\Q$, its roots are all the primitive $n$-th roots of
unity, hence $\deg\Cyclo_n=\euler(n)$.

Let $\LK/\K$ be a finite Galois extension and let $x\in\LK$, the map
$M_x:a\mapsto xa$ is an automorphism of the $\K$-vector space
$\LK$. The minimal polynomial of its matrix with respect to any basis
is equal to the minimal polynomial of $x$ over $\K$.  The trace of
$M_x$ is called the \index{trace!of~an~element}\textbf{trace} of $x$
and is denoted by $\Tr_{\LK/\K}(x)$; its determinant is called the
\index{norm}\textbf{norm} of $x$ and is denoted by
$\Norm_{\LK/\K}(x)$.

\begin{proposition}
  \label{th:basic-galois-theory:trace}
  Let $\LK/\K$ and $\K/k$ be field extensions and let
  $G=\Gal(\LK/\K)$. We have the following identities
  \begin{align*}
    \Tr_{\LK/\K}(x) &= \sum_{\sigma\in G}\sigma(x) \text{,}&
    \Tr_{\LK/k} &= \Tr_{\K/k}\circ\Tr_{\LK/\K}\text{,}\\
    \Norm_{\LK/\K}(x) &= \prod_{\sigma\in G}\sigma(x) \text{,}&
    \Norm_{\LK/k} &= \Norm_{\K/k}\circ\Norm_{\LK/\K}\text{.}
  \end{align*}
  The trace is an additive morphism of $\K$-vector spaces from $\LK$
  to $\K$, the norm is a multiplicative morphism of groups from
  $\LK^\ast$ to $\K^\ast$.
\end{proposition}


\subsection{Finite fields}
\label{sec:basic-galois-theory:finite-fields}

Let $\K$ be a \index{field!finite} \index{finite~field} \textbf{finite
  field}. It has necessarily characteristic $p>0$, thus it must
contain $\Z/p\Z$ as a subfield. $\Z/p\Z$ is called the
\index{field!prime} \index{prime~field}\textbf{prime field} of $\K$
and is denoted by $\F_p$. Since $\K$ is a vector space over $\F_p$, it
must have cardinality $q=p^n$ for some $n$, hence its multiplicative
group has order $q-1$.

As a consequence, the elements of $\K^\ast$ must be roots of the
polynomial $X^{q-1}-1$. The fact that $p$ does not divide $q-1$
implies that $\K$ is the subfield of $\F_p[\zeta]$ where $\zeta$ is a
primitive $q-1$-th root of unity in $\clot{\F}_p$. This implies that,
up to isomorphism, there is an unique finite field containing $q$
elements, we denote by $\F_q$ this field.

Using the same arguments, it is easy to show that for any $m\ge 1$,
$\F_{q^m}$ contains a subfield isomorphic to $\F_q$.  For any element
of $\F_q^m$, the mapping $\frob_q:x\mapsto x^q$ is a morphism of
fields that fixes $\F_q$, it is called the
\index{Frobenius!automorphism}\textbf{Frobenius automorphism} of
$\F_{q^m}/\F_q$. We now give the main result about the Galois theory
of finite fields.

\begin{proposition}
  The Galois group of $\F_{q^m}/\F_q$ is a cyclic group of order $m$;
  it is generated by the Frobenius automorphism $\frob_q$.
\end{proposition}



%%% Local Variables: 
%%% mode:flyspell
%%% ispell-local-dictionary:"american"
%%% mode: TeX-PDF
%%% mode: reftex
%%% TeX-master: "../these"
%%% End: 


