Here we recall the concepts from abstract algebra that will constitute
the background for all the chapters that follow. One chapter is
certainly not enough to present such a vast subject, hence we just
recall the few definitions and properties that will help the reader
understand the results presented in this document. The material of
this chapter is mainly drawn from
\cite{lang,lidl+niederreiter:2,silverman:elliptic}.

% \section{Groups, Rings, Modules}
% \label{sec:ring-fields}

% \subsection{Objects}
% \label{sec:ring-fields:objects}

% \subsubsection{Groups}

% A \index{group}\textit{group} is a pair $(G,\cdot)$ such that $G$ is a
% set and $\cdot:G\times G\ra G$ is an \emph{internal composition law}
% satisfying:
% \begin{itemize}
% \item \index{associativity}\textit{Associativity}: $(a\cdot b)\cdot c
%   = a \cdot (b\cdot c)$ for any $a,b\in G$;
% \item There is an element $e\in G$, called the
%   \index{identity~element}\textit{identity}, such that $a\cdot e =
%   e\cdot a = a$ for any $a\in G$;
% \item For any $a\in G$ there is an
%   \index{inverse~element}\textit{inverse element} $b$ such that
%   $a\cdot b = b\cdot a = e$.
% \end{itemize}
% If $\cdot$ also satisfies $a\cdot b=b\cdot a$
% (\index{commutativity}\textit{commutativity}), the group is said to be
% \index{group!abelian}\textit{abelian}. The group composed of one
% single element with the obvious law is called the
% \index{group!trivial}\textit{trivial group}.

% A \index{subgroup}\textit{subgroup} of a group $(G,\cdot)$ is a group
% $(H,\circ)$ such that $H\subset G$ and $\circ$ is the restriction of
% $\cdot$ to $H$. Any group has two trivial subgroups: the trivial group
% and itself. The \index{opposite!group}
% \index{group!opposite~group}opposite group of a group $(G,\cdot)$ is
% the group $(G,\cdot^\op)$ where $a\cdot^\op b=b\cdot a$ for any
% $a,b\in G$.

% The \index{center!of~a~group} \index{group!center}\textit{center} of
% $(G,\cdot)$ is the subgroup formed by the elements $a\in G$ such that
% $a\cdot b=b\cdot a$ for any $a\in G$. The center is clearly a
% commutative group.

% Let $A$ be a subset of $G$, the group
% \index{group!generator}\index{generator!of~a~group}\textit{generated}
% by $A$, denoted by $\langle A\rangle$, is the smallest subgroup of
% $(G,\cdot)$ containing $A$. A finite group generated by a single
% element is said to be
% \index{cyclic!group}\index{group!cyclic}\textit{cyclic}; a cyclic
% group is necessarily abelian.

% Let $(G,\cdot)$ be a group, $(H,\cdot)$ a subgroup and $g\in G$. The
% subset $g\cdot H = \{g\cdot h | h \in H \}$ of $G$ is called a
% \index{coset!left~coset}\textit{left coset} of $H$, or simply
% \index{coset}coset. A \index{coset!right~coset}\textit{right coset},
% denoted by $H\cdot g$, is a left coset for the opposite group; when
% $G$ is abelian the two notions coincide. A subgroup $H$ is called
% \index{subgroup!normal}normal if $g\cdot H=H\cdot g$ for any $g\in G$;
% note that if $G$ is abelian, any subgroup is normal. Let $H$ be
% normal, the cosets of $H$ form a group under the law $(g\cdot
% H,g'\cdot H)\mapsto (g\cdot g')\cdot H$, this group is called the
% \index{quotient!of~groups}\textit{quotient} of $G$ by $H$ and is
% denoted by $G/H$.

% Let $S$ be a set and let $G$ be a group. A
% \index{group~action!left~group~action}
% \index{group~action}\textit{(left) group action} of $G$ over $S$ is a
% law $.:G\times S\ra S$ such that for any $g,g'\in G$ and $x\in S$,
% \begin{itemize}
% \item $g'.(g.x) = (g'\cdot g). x$,
% \item $e. x = x$.
% \end{itemize}
% A \index{group~action!right~group~action}\textit{right group action}
% is a left group action for the opposite group.


% \subsubsection{Rings, Fields}

% A \index{ring}\textit{ring} is a tuple $(R,+,\cdot)$ such that $(R,+)$
% is an abelian group and $\cdot:R\times R\ra R$ is an internal
% composition law satisfying associativity, existence of the identity
% and \index{distributivity}\textit{distributivity} over $+$
% \[a \cdot (b + c) = (a\cdot b) + (a\cdot c) \quad\text{for any
%   $a,b,c\in R$.}\] When $\cdot$ satisfies commutativity, the ring is
% said to be \index{ring!commutative}\textit{commutative}.  The law $+$
% is called \emph{addition}, $\cdot$ is called \emph{multiplication},
% the identity for $+$ is denoted by $0$ and the identity for $\cdot$ by
% $1$.  A commutative ring such that $1\ne 0$ and where $\cdot$ also
% satisfies the existence of the inverse, is called a
% \index{field}\textit{field}.

% The group $(R,+)$ is called the \index{additive~group}\textit{additive
%   group} of $R$. Let $R^\ast$ be the subset consisting in the elements
% of $R$ that have both a left and a right inverse for $\cdot$, the
% group $(R^\ast,\cdot)$ is called the
% \index{multiplicative~group}\textit{multiplicative group} or the
% \index{group!of~units}\textit{group of units} of $R$.

% A \index{subring}\textit{subring} of a ring $(R,+,\cdot)$ is a ring
% $(S,\ast,\circ)$ such that $(S,\ast)$ is a subgroup of $(R,+)$ and
% $\circ$ is the restriction of $\cdot$ to $S$.  The
% \index{opposite!ring}\index{ring!opposite~ring}\textit{opposite ring}
% of a ring $(R,+,\cdot)$ is the ring $(R,+,\cdot^\op)$
% where $a\cdot^\op b=b\cdot a$ for any $a,b\in R$.

% The simplest example of ring is $\Z$, the set of integers; the
% rational numbers $\Q$ are an example of field, it is the
% \emph{smallest} field containing $\Z$ as a subring. The
% \index{ring!trivial}\textit{trivial ring} is the ring composed of one
% unique element $r=0=1$ with the evident laws; note that by definition
% this is not a field.

% \subsubsection{Modules, ideals, vector spaces}

% Given a ring $(R,+,\cdot)$ a \index{module!left~module}\textit{left
%   module}, or simply \textit{module}, over $R$ is a tuple $(M, +_M,
% \cdot_M)$ such that $(M,+_M)$ is an abelian group and $\cdot_M:R\times
% M\ra M$ is an \emph{external law} such that for any $r,r'\in R$ and
% $m,m'\in R$
% \begin{itemize}
% \item $(r + r')\cdot_M m = (r \cdot_M m) +_M (r'\cdot_M m)$,
% \item $r\cdot_M(m +_M m') = (r\cdot_M m) +_M (r'\cdot_M m)$,
% \item $r'\cdot_M(r\cdot_M m ) = (r'r)\cdot_M m$,
% \item $1\cdot_M m = m$.
% \end{itemize}
% The law $+_M$ is called \emph{addition}, its identity is denoted by
% $0$; the law $\cdot_M$ is called
% \index{multiplication!scalar}\index{scalar~multiplication}\textit{scalar}
% or
% \index{mutliplication!external}\index{external~multiplication}\textit{external}
% multiplication. 

% A \index{module!right~module}\textit{right module} is a left module
% for the opposite ring $R^\op$, a
% \index{module!two-sided}\textit{two-sided module} also called
% \index{bimodule}\textit{bimodule} is an object that is both a left and
% a right module. When $R$ is commutative, the three notions coincide
% and we simply speak of a \index{module}\textit{module}.  $R$-module is
% another way of saying ``module over $R$''. When $\K$ is a field, a
% $\K$-module is called a \index{vector~space}\textit{$\K$-vector
%   space}. When $R$ is commutative, a ring $S$ that is also an
% $R$-module is called an \index{algebra}\textit{$R$-algebra}.

% A \index{module!submodule}\index{submodule!left~submodule}left
% (\index{submoudle!right~submodule}right,
% \index{submodule!two-sided}two-sided) \textit{submodule} of a left
% (right, two-sided) $R$-module $(M,+,\cdot)$ is a left (right, two-sided)
% $R$-module $(N,\ast,\circ)$ such that $(N,\ast)$ is a subgroup of
% $(M,+)$ and $\circ$ is the restriction of $\cdot$ to $R\times N$.

% Let $A$ be a subset of $M$, the module
% \index{group!generator}\index{generator!of~a~group}\textit{generated}
% by $A$, denoted by $\langle A\rangle$ or $(A)$, is the smallest
% submodule of $(M,+,\cdot)$ containing $A$.

% The module containing one unique element with the evident laws is
% called the \index{module!zero~module}\textit{zero module}; any
% $R$-module contains a submodule that is isomorphic to the zero module.
% Any abelian group $(G,+)$ can be given a $\Z$-module structure by the
% law
% \[n\cdot g = \underbrace{g + \cdots + g}_{n\text{ times}} \text{.}\]
% The \index{order!of~an~element}\textit{order} of an element $g$ is the
% smallest strictly positive integer $n$ such that $n\cdot g=e$; if no
% such $n$ exists, $g$ is said to have
% \index{order!infinite}\textit{infinite order}. When a group is finite,
% we also call \index{order!of~a~group}\textit{order} its cardinality;
% the order of any element divides the order of the group.

% In particular any ring is a $\Z$-algebra. The
% \index{characteristic}\textit{characteristic} of a ring $(R,+,\cdot)$
% is the order of $1$ in $(R,+)$. By convention we say that the
% characteristic is $0$ if $1$ has infinite order. The characteristic of
% a field can only be $0$ or a prime number.

% Any ring $R$ is trivially a two-sided module over itself; a
% \index{ideal!left~ideal} (\index{ideal!right~ideal}right,
% \index{ideal!two-sided}two-sided) \textit{ideal} of a ring $R$ is a
% submodule of the left (right, two-sided) $R$-module $R$.  When $R$ is
% commutative one simply speaks of an \index{ideal}ideal.  

% Any ring contains at least two submodules: the zero module and itself;
% these are called the \index{ideal!trivial}\textit{trivial ideals}. The
% only non-trivial ideals of $\Z$ are the $n\Z$ for any $n\ne0,1$. A
% field has no non-trivial ideals.

% The \index{direct~sum}\textit{direct sum} $M\oplus N$ of two
% $R$-modules $(M,+_M,\cdot_M)$ and $(N,+_N,\cdot_N)$ is the module
% $(M\times N,+,\cdot)$ where the laws $+$ and $\cdot$ are defined
% component-wise. This generalizes to sums of an arbitrary number of
% modules: let $(M_i)_{i\in I}$ be a sequence of $R$-modules, the direct
% sum $\bigoplus_{i\in I}M_i$ is the $R$-module whose elements are the
% sequences $(m_1,m_2,\ldots)$ where $m_i\in M_i$ and $m_i=0$ for all
% but a finite number of them; the laws are defined component-wise.
% Although less commonly used, there also exists a notion of
% \index{direct~product}\textit{direct product}: given $(M_i)_{i\in I}$,
% the direct product $\prod_{i\in I}M_i$ is the $R$-module whose
% elements are the sequences $(m_1,m_2,\ldots)$ where $m_i\in M_i$ with
% the laws defined component-wise. Clearly, the two definition coincide
% when $I$ is a finite set.

% When $R$ is seen as an $R$-module over itself, we denote by $R^n$ the
% direct sum $\bigoplus_{0<i\le n}R$ and by $R^\infty$ the direct sum
% $\bigoplus_{i>0}R$. An $R$-module that is isomorphic to the direct sum
% $\bigoplus_{I}R$ for some $I$ is called a
% \index{module!free}\textit{free module}. A \index{basis}\textit{basis}
% of a module $M$ is a family $(m_i)_{i\in I}$ of elements of $M$ such
% that any $m\in M$ can be written as 
% \begin{equation}
%   \label{eq:module-basis}
%   m = \sum_{i\in I} r_i\circ m_i
%   \quad\text{with $r_i\in R$}
% \end{equation}
% in an unique way. Clearly, if we denote by $e_i$ the element of
% $\bigoplus_IR$ that has $1$ in the $i$-th position and $0$ elsewhere,
% the family $(e_i)_{i\in I}$ forms a basis; hence, any free module has
% a basis and, conversely, any module that has a basis is free. One
% important statement about bases of modules is the following.

% \begin{proposition}
%   \label{th:invariant-basis}
%   Any two bases for a free module $M$ over a commutative ring $R$ have
%   the same cardinality.
% \end{proposition}

% For this reason, when $M$ is a free module over a commutative ring $R$
% we call \index{dimension} \index{dimension!of~a~module}
% \index{module!free!dimension~of} \index{dimension!of~a~bector~space}
% \index{vector~space!dimension~of}\textit{dimension} the cardinality of
% any of its bases. It is a well known result in linear algebra that any
% vector space has a basis, hence any $\K$-vector space is free as a
% $\K$-module.

% Given a module $M$ and a submodule $N$, the quotient group $M/N$ can
% be given a module structure by the law $r\cdot(m+N)=(r\cdot m)+N$, it
% is then called the \index{quotient!of~modules}\textit{quotient
%   module}. When $R$ is a ring and $I$ a module, the quotient $R/I$ can
% also be given a ring structure by the law $(r+I)\cdot(r'+I)=(r\cdot
% r')+I$, it is then called the \index{quotient!of~ring}\textit{quotient
%   ring}.

% In what follows we will follow the common practice and abuse the
% notation in several ways:
% \begin{itemize}
% \item When different groups (rings, modules) are involved in a
%   statement, we will often use the same symbols for all the group
%   (ring, module) laws; the context will always make clear which group
%   law is involved.
% \item We will often use sentences like ``Let $G$ be a group (ring,
%   module)'' without explicitly giving the symbols for the laws: the
%   symbols $+$ and $\cdot$ are then implied. A
%   \index{additive~notation}
%   \index{group!written~additively}\textit{group written additively}
%   will be a group whose law is denoted by $+$; a
%   \index{multiplicative~notation}
%   \index{group!written~multiplicatively}\textit{group written
%     multiplicatively} will be a group whose law is denoted by $\cdot$.
% \item Recall that any abelian group is a $\Z$-module. For a $g\in G$,
%   the external multiplication by an element $n\in\Z$ will be written
%   $n\cdot g$ or $ng$ in additive notation, $g^n$ in multiplicative
%   notation.
% \item The operator $\cdot$ will always have higher precedence than
%   $+$, and it will often be omitted. Thus $ab+cd$ is just a compact
%   notation for $(a\cdot b) + (c\cdot b)$.
% \item To avoid ambiguities, in particular when the $\cdot$ operator is
%   omitted, the elements of the opposite group/ring will be denoted by
%   $a^\op$ for any $a\in G$. Thus $a^\op b^\op=(ba)^\op$.
% \end{itemize}


% \subsection{Arrows}
% \label{sec:ring-fields:arrows}

% Given two groups $G$ and $G'$, a
% \index{morphism!of~groups}\textit{morphism} from $G$ to $G'$,
% sometimes also called a
% \index{homomorphism|see{morphism}}\textit{group homomorphism}, is a
% mapping $f:G\ra G'$ that \emph{commutes} with the group law and
% \emph{preserves} the identity, that is
% \begin{itemize}
% \item $f(a\cdot b) = f(a) \cdot f(b)$,
% \item $f(e) = e$.
% \end{itemize}

% A \index{morphism!of~rings}\textit{morphism of rings} is a group
% morphism that commutes with multiplication and preserves $1$, a
% \index{morphism!of~modules}\textit{morphism of modules} is a group
% morphism that commutes with the external multiplication.

% The \index{kernel}\textit{kernel} of a group morphism $f:G\ra G'$,
% denoted by $\ker f$, is the subgroup of $G$ consisting of the elements
% such that $f(g)=e$. The kernel of a ring (module) morphism is the
% kernel of the underlying group morphism.

% The \index{image}\textit{image} of a group morphism $f:G\ra G'$,
% denoted by $\im f$, is the subgroup of $G'$ consisting of the elements
% $g'$ such that $f(g)=g'$ for some $g\in G$. The image of a ring
% (module) morphism is the image of the underlying group morphism.

% A morphism $f:A\ra B$ is said to be
% \index{morphism!injective}\textit{injective} is its kernel is the zero
% subgroup of $A$, \index{morhpism!surjective}\textit{surjective} if its
% image is the whole $B$, \index{morphism!bijective}\textit{bijective}
% if it is both. A bijective morphism is also called an
% \index{isomorphism}\textit{isomorphism}, two groups (rings, modules)
% such that there is an isomorphism between them are said to be
% \index{isomorphic}\textit{isomorphic}, if $A$ and $B$ are isomorphic
% we write $A\isom B$. A morphism $f:A\ra A$ is also called an
% \index{endomorphism}\textit{endomorphism}, a bijective endomorphism is
% called an
% \index{automorphism}\textit{automorphism}. 

% Sometimes, in the special case of $R$-module morphisms, we say
% \index{linear!map}\textit{$R$-linear map} instead of morphism, and
% \index{linear!operator}\textit{$R$-linear operator} on $M$ instead of
% endomorphism of $M$. Linear maps $f:M\ra R$ are also called
% \index{form!linear|see{linear}} \index{linear!form}\textit{$R$-linear
%   forms}.

% \begin{proposition}
%   \label{th:first-isomorphism}
%   The kernel of a group morphism $f:A\ra B$ is a normal subgroup of
%   $A$ and the image is a subgroup of $B$.  If $f$ is a ring morphism,
%   $\ker f$ is an ideal and $\im f$ a subring. If $f$ is a module
%   morphism, $\ker f$ and $\im f$ are both submodules.
  
%   In each of these cases $\im f$ is isomorphic to $A/\ker f$ as a
%   group/ring/module.
% \end{proposition}

% \index{morphism!zero~morphism} \textit{Zero morphisms} are those
% morphisms $f:A\ra B$ such that $\ker f = A$.  An easy consequence of
% the proposition is that, since a field has no non-trivial ideals, any
% non-zero morphism of fields is injective; for this reason a morphism
% from a field $\K$ to a field $\LK$ is also called an
% \index{embedding}\textit{embedding} of $\K$ into $\LK$.

% The set of group/ring/module morphisms from $A$ to $B$ is denoted by
% $\hom(A,B)$. If $A$ and $B$ are (abelian) groups, then $\hom (A,B)$ is
% a (abelian) group by the law $(f\cdot g)(a) = f(a)\cdot g(a)$. If $A$
% and $B$ are $R$-modules, the set of morphisms of modules may also be
% written $\hom_R(A,B)$ if the ring is not clear from the context; if
% $A$ and $B$ are right modules, the set of morphisms is conveniently
% written as $\hom_{R^\op}(A,B)$. In general $\hom_R(A,B)$ and
% $\hom_{R^\op}(A,B)$ are only abelian groups, but when $R$ is
% commutative they are equal and they also have an $R$-module structure
% by the law $(a\cdot f)(b) = a\cdot f(b)$.

% If $A$ is a group/ring/module, $\hom(A,A)$ has a ring structure by the
% law $f\cdot g=f\circ g$, where $\circ$ is composition of functions. It
% is called the \index{ring!of~endomorphisms}
% \index{endomorphism~ring}endomorphism ring of $A$ and is denoted by
% $\End(A)$. When $A$ is a module over a commutative ring and we want to
% stress the fact that $\End(A)$ is an $R$-algebra, we write
% $\End_R(A)$. We denote by $\Aut(A)$ the multiplicative subgroup of
% $\End(A)$, it is the group of automorphisms of $A$.

% Let $M$ be a left $R$-module, then $\hom_R(M,R)$ is a right $R$-module
% by the law $(a^\op \cdot f)(b) = f(b)\cdot a$; similarly, if $M$ is a
% right $R$-module, $\hom_{R^\op}(M,R)$ is a left $R$-module (a right
% $R^\op$-module). Both are called the
% \index{module!dual~module}\index{dual!of~a~module}\textit{dual module}
% of $M$ and are denoted by $\dual{M}$.

% A convenient way of expressing properties of morphisms is to draw
% \index{diagram}\textit{diagrams} where objects (groups, rings, etc.)
% are connected by arrows representing morphism. A diagram
% \[\xymatrix{A\ar[r]^f\ar[dr]_h & B \ar[d]^g\\&C}\]
% is said to be \index{diagram!commutative}\textit{commutative} if
% $g\circ f = h$. In general, we call \index{sequence}\textit{sequence}
% any sequence of consecutive arrows in a diagram. A diagram is
% commutative if, whenever two sequences
% \[\xymatrix{A\ar[r]^{f_1} & \cdots \ar[r]^{f_n} & B}\]
% and
% \[\xymatrix{A\ar[r]^{g_1} & \cdots \ar[r]^{g_n} & B}\]
% connect the same two objects, $f_1\circ\cdots\circ
% f_n=g_1\circ\cdots\circ g_m$.  A sequence
% \[\xymatrix{\cdots \ar[r] & A_{i-1}\ar[r]^{f_{i-1}} & A_i \ar[r]^{f_i}
%   & A_{i+1} \ar[r] & \cdots}\]
% is said to be \index{sequence!exact}
% \index{exact~sequence}\textit{exact} if $\ker f_i = \im f_{i-1}$ for
% any $i$.


\section{Linear algebra}
\label{sec:linear-algebra}
In Part~\ref{part:transp-princ} we shall apply some classical linear
algebraic tools to free modules over non-commutative ring. We recall
here the fundamental concepts.


\subsection{Bra-ket notation}
\label{sec:linear-algebra:bra-ket}

It will be convenient to (ab)use Dirac's
\index{bra-ket~notation}bra-ket notation to represent elements of
modules. If $(M,+,\cdot)$ is a left $R$-module and $x\in (M,+)$ is an
element of its underlying group, by $\ket{x}_R$ we mean the element
obtained by lifting $x$ in $(M,+,\cdot)$. We call
$\ket{x}$\symb[braket-1]{$\ket{x}$}{Ket, element of a left module} a
\index{ket}\textit{ket} and read it as ``ket x''.

The external multiplication by an element $a\in R$ will be written
$a\ket{x}_R$; if $f:M\ra N$ is a left module morphism, we write
$f\ket{x}_R$ for $f(\ket{x}_R)$. By a slight abuse of notation we may
write $\ket{a x}_R$ and $\ket{f(x)}_R$ for $a\ket{x}_R$ and
$f\ket{x}_R$ respectively. When $R$ is clear from the context, a ket
can be simply written as $\ket{x}$\symb[braket-2]{$\bra{x}$}{Bra,
  element of a right module}.

In a symmetric way, elements of right $R$-modules will be written
${}_R\bra{x}$, which we call a \index{bra}\textit{bra} and read as
``bra x''. External multiplication will be written as ${}_R\bra{x}a$
and application of a right module morphism as ${}_R\bra{x}f$.

Let $M$ be a right module and $N$ a left module. A
\index{bilinear~form}\textit{bilinear
  form}\symb[braket-3]{$\braket{x}{y}_f$}{Bilinear form} on
$M\times N$ is a map $f:M\times N\ra R$ such that for any $x\in M$,
the map
\[\ket{y}\mapsto f(x, y)\]
is a left module morphism, and for any $y\in N$, the map
\[\bra{x}\mapsto f(x, y)\]
is a right module morphism. If $f$ is a bilinear form, we write
$\braket{x}{y}_f$ for $f(x,y)$, or simply $\braket{x}{y}$
when $f$ is clear from the context. Note that textbooks usually define
bilinear forms only when $R$ is commutative, in our more general
setting some common properties of bilinear forms fail to hold,
for example $\braket{xa}{y}\ne\braket{x}{ay}$.

If $M$ is a left (right) module, we denote by $\dual{M}=\hom(M,R)$ the
\index{dual~module}\textit{dual
  module}\symb[dual]{$\dual{M}$}{Dual of a module or vector
  space: $\dual{M}=\hom(M,R)$} of $M$, it is a right (left) module.
Any bilinear form $f$ gives rise to a morphism $ \phi_f : M \ra
\dual{N}$ of right modules where $\bra{x}\phi_f$ is the linear form $y
\mapsto \braket{x}{y}$. Similarly, $f$ gives rise to a morphism
$\phi^f:N\ra\dual{M}$ of left modules. The maps $f\mapsto\phi_f$,
$f\mapsto\phi^f$ and their obvious inverses induce group isomorphisms
between $\hom(M,\dual{N})$, $\hom(N,\dual{M})$ and the group of
bilinear forms on $M\times N$.  A bilinear form $f$ is said to be
\index{bilinear~form!degenerate}\textit{non-degenerate} if $\phi_f$
and $\phi^f$ are module isomorphisms.
\pdfmcone{The distinction
  non-singular/non-degenerate comes from Lang, but it is not very
  standard, indeed. I removed the distinction: now I call
  non-degenerate what I used to call non-singular before.}


\subsection{Matrices and morphisms}
\label{sec:linear-algebra:matrices}
$M=M_1\oplus\cdots\oplus M_n$ be a left module and
$N=N_1\oplus\cdots\oplus N_m$ be a right module.  Let $\iota_i$ be the
injections $M_i\ra M$ and let $\pi_j$ be the projections $N\ra N_i$,
then a linear map $f:M\ra N$ is uniquely determined by the maps
$\pi_j\circ f\circ\iota_i$. If we consider $m\times n$ matrices whose
$(j,i)$-th coefficient is in $\hom(M_i,N_j)$, then we verify that
there is a group isomorphism between $\hom(M,N)$ and this group of
matrices. Furthermore, let $f:M\ra N$ and $g:N\ra O$ and let $M_f$ and
$M_g$ be the matrices that are associated respectively, then the
matrix associated to $g\circ f$ is $M_gM_f$, where the product of two
entries is defined as composition of morphisms. This induces a ring
isomorphism between $\End(M)$ and the ring of square matrices with
entries in $\hom(M_i,M_j)$.

Consider $R$ as an $R$-module over itself, a linear map from $R$ to
itself is uniquely determined by the image of $1$, hence $\End(R)\isom
R^\op$. As a consequence, there is a group isomorphism
$\hom(R^n,R^m)\isom\Mat_{m\times n}(R^\op)$ and matrix multiplication
is equivalent to composition as above.  Hence, if $M$ is a free
module, for any fixed basis $\basis{B}$ of cardinality $n$ we have an
isomorphism of rings $\End_R(M)\isom\Mat_n(R^\op)$; in particular
$\Aut(M)\isom\GL_n(R^\op)$ as groups.

Let $R$ be commutative, then $R^\op = R$. We denote by
$M_{\basis{B}}(f)$ the matrix associated to $f\in\End_R(M)$ with
respect to the basis $\basis{B}$.  If $\basis{B'}$ is another basis,
it has the same cardinality as $\basis{B}$. Then, there is an
invertible matrix $B$ such that $A\mapsto B^{-1}AB$ is the
automorphism of $\Mat_n(R)$ that sends $M_{\basis{B}}(f)$ over
$M_{\basis{B'}}(f)$. Hence, any property of matrices that is invariant
by similarity, can be defined for linear operators. We define the
\index{trace!of~an~operator} \index{trace}\textit{trace} of a linear
operator as $\Tr f = \Tr M(f)$\symb[Tr]{$\Tr$}{Trace of a
  matrix, of a linear operator}, and its
\index{determinant}\textit{determinant} as $\det f = \det
M(f)$\symb[det]{$\det$}{Determinant of a matrix, of a linear
  operator}.


\subsection{Duality}
\label{sec:linear-algebra:duality}
We fix a non-degenerate bilinear form $f$ on $M\times N$. Let
$g\in\End(M)$, then the map
\[(x,y) \mapsto \braket{g(x)}{y}_f\] is a bilinear form. On the other
hand, let $h$ be a bilinear form on $M\times N$, for any $x\in M$ the
map $h_x : \ket{y} \mapsto \braket{x}{y}_h$ is a linear form on $N$,
thus $h_x\in\dual{N}$. From the non-degeneracy of $f$ we deduce that
there is an unique element $x'\in M$ such that
$\braket{x'}{y}_f=\braket{x}{y}_h$ and it is clear that the map
$\bra{x}\mapsto \bra{x'}$ is an endomorphism of $M$. It is evident
that the two maps are each other's inverse, thus we have a group
isomorphism between $\End(M)$ and the group of bilinear forms. An
analogous argument shows that $\End(N)$ is isomorphic to the group of
bilinear forms and ultimately $\End(M)\isom\End(N)$.

A consequence of this is that for any linear operator $g\in\End(M)$
there is an operator $\dual{g}\in\End(N)$ such that
\[\braket{g(x)}{y}_f = \braket{x}{\dual{g}(y)}_f\]
for any $x\in M$ and $y\in N$. We define similarly $\dual{h}$ when
$h\in\End(N)$, obviously $\dual{(\dual{g})} = g$. The operator
$\dual{g}$ is called the
\index{dual~operator}\textit{dual}\symb[dual]{$\dual{g}$}{Dual
  operator: $\braket{g(x)}{y}=\braket{x}{\dual{g}(y)}$} of $g$ with
respect to $f$. In general, whenever it is clear from the context that
$g$ belongs to $\End(M)$ (or to $\End(N)$), we simply
write\symb[braket-4]{$\braketop{x}{g}{y}$}{Bilinear form with linear operator}
\[\braketop{x}{g}{y} \eqdef \braket{g(x)}{y} = \braket{x}{\dual{g}(y)}\text{.}\]

More generally, Let $f:M\times M'\ra R$ and $g:N'\times N\ra R$ be two
non-degenerate bilinear forms, by the same technique as above we can
show that there is a group isomorphism between $\hom_R(N,M')$,
$\hom(M,N')$ and the bilinear forms on $M\times N$. Then, for any
$h:N\ra M'$ there is an unique $\dual{h}:M\ra N'$ such that
\[\braketop{x}{h}{y}\eqdef\braket{x}{h(y)}_f = \braket{\dual{h}(x)}{y}_g 
\text{.}\]
We also call $\dual{h}$ the \textit{dual} of $h$.

The canonical example of non-degenerate bilinear forms is obtained by
considering the family of forms on $\dual{M}\times M$ defined by
\[\braket{\ell}{x} = \ell(x) \text{.}\]
For any $f:M\ra N$, we define the dual map
$\dual{f}:\dual{N}\ra\dual{M}$ as the map that sends a form
$\ell\in\dual{N}$ over the form $\ell\circ f$ in $\dual{M}$; it is
easy to verify that
\[\braketop{\ell}{f}{x} =  \braket{\ell}{f(x)} = \braket{\dual{f}(\ell)}{x}
= \ell(f(x))\text{.}\]


\pdfmcone{Introduced definition of dual basis, clarified messy
  comments about columns and vectors.}  If $M$ is a free module and
$\basis{B}=\{\basis{e}_1,\ldots,\basis{e}_n\}$ a basis, the
\index{dual~basis}\textit{dual basis} $\dual{\basis{B}}$ is the unique
basis $\{\dual{\basis{e}_1},\ldots,\dual{\basis{e}_1}\}$ of $\dual{M}$
such that
\begin{equation*}
  \braket{\dual{\basis{e}_i}}{\basis{e}_j} =
  \begin{cases}
    1 &\text{if $i=j$,}\\
    0 &\text{if $i\ne j$.}
  \end{cases}
\end{equation*}
If elements of $M$ and $\dual{M}$ are represented, respectively, as
vectors over $\basis{B}$ and $\dual{\basis{B}}$, then the bilinear
form $\braket{\ell}{x}=\ell(x)$ is given by the inner product
\begin{equation*}
  \left\langle\begin{matrix}
      \ell_1 &\cdots & \ell_n
    \end{matrix}\right\rvert
  \left\lvert\begin{matrix}
    x_1\\
    \vdots\\
    x_n
  \end{matrix}\right\rangle
  =
  \sum_i x_i\ell_i
\end{equation*}
(notice how the product is swapped, this is because $\End(R)\isom
R^\op$).  Now, if $M$ and $N$ are free modules with a fixed basis, a
linear map $f:M\ra N$ is isomorphic to a matrix with entries in
$R^\op$. Then the application $f\ket{x}$ is just matrix-vector
multiplication, while $\bra{\ell}\dual{f}$ is vector-matrix
multiplication by the same matrix. This justifies the notation
$\braketop{\ell}{A}{x}$ where $A$ is the matrix associated to $f$.


\section{Basic Galois theory}
\label{sec:basic-galois-theory}
In Parts~\ref{part:fast-arithm-using} and~\ref{part:appl-isog-comp} we
shall need some basic Galois theory of finite fields. We recall here
the general concepts.

\subsection{Galois extensions}
\label{sec:basic-galois-theory:galois-extensions}
\pdfmcone{Removed pastiche about splitting fields} Let $\K$ be
a field. The \index{splitting~field}\textit{splitting field} of a
family of polynomials $(Q_i)_{i\in I}$ in $\K[X]$ is defined as an
extension $\LK$ of $\K$ where all the $Q_i$ factor completely into
linear factors and such that $\LK$ is generated over $\K$ by the roots
of the $Q_i$; the splitting field is unique up to isomorphism. An
algebraic field extension $\LK/\K$ such that $\LK$ is the splitting
field of a family of polynomials in $\K[X]$ is called a
\index{normal~field~extension}\textit{normal extension}.

Let $\LK/\K$ be an algebraic field extension, an element $x\in\LK$ is
said to be \index{separable!element}\textit{separable} over $\K$ if
its minimal polynomial over $\K$ has no multiple roots in $\LK$.
$\LK/\K$ is said to be \index{separable!field~extension}
\textit{separable} if every $x\in\LK$ is separable over $\K$. An
algebraic field extension is said to be a
\index{Galois~field~extension}\textit{Galois extension} if it is both
separable and normal.

\begin{theorem}
  Let $\LK/\K$ be a finite Galois extension, then there exists an
  element $x\in\LK$, called a
  \index{primitive!element}\textit{primitive element}, such that
  $\LK\isom\K[x]$.
\end{theorem}

Let $\LK/\K$ be a Galois extension, the group of automorphisms of
$\LK$ that fix $\K$ is called the \index{Galois~group}\textit{Galois
  group} of $\LK/\K$ and is denoted by
$\Gal(\LK/\K)$\symb[Gal]{$\Gal(\LK/\K)$}{Galois group}.  Let
$G$ be a group of automorphisms of a field $\K$, by
$\K^G$\symb[KG]{$\K^G$}{Fixed field, the subfield of $\K$
  fixed by the action of $G$} we denote the subfield of $\K$
consisting in the elements such that $\sigma(x)=x$ for any $\sigma\in
G$. Obviously, $\K=\LK^{\Gal(\LK/\K)}$.

\begin{theorem}
  Let $\LK/\K$ be a finite Galois extension. Let $H$ be a subgroup of
  $G=\Gal(\LK/\K)$, the map $H\mapsto \LK^H$ is a bijection between
  the subgroups of $G$ and the subfields of $\LK$ containing $\K$. The
  extension $\LK^H/\K$ is Galois if and only if $H$ is a normal
  subgroup of $G$; in this case its Galois group is isomorphic to
  $G/H$.
\end{theorem}

Let $\LK/\K$ be a Galois extension and let $x\in\LK$. The elements
$\sigma(x)$ for $\sigma\in\Gal(\LK/\K)$ are called the
\index{conjugate~element}\textit{conjugates} of $x$ under the action
of $\Gal(\LK/\K)$; they are the roots of the minimal polynomial of $x$
over $\K$.

Let $\K$ be a field, an element $x\in \K$ such that $x^n=1$ is called
an $n$-th \index{root~of~unity}\textit{root of unity}. If the
characteristic of $\K$ does not divide $n$, the polynomial $X^n-1$ has
$n$ distinct roots in $\clot{\K}$ and they form a multiplicative
group, denoted by $\mu_n$. $\mu_n$ is a cyclic group, its generators
are called the \index{root~of~unity!primitive} \textit{primitive}
roots of unity.  If $\K$ has characteristic $p>0$, then $X^{p^m}-1$
has only one root, namely $1$, thus $\mu_{p^m}$ is the trivial group.

The \index{Euler~function}\textit{Euler function}
$\euler:\N\ra\N$\symb[f]{$\euler$}{Euler totient function} is
defined as
\begin{align*}
  \euler(1) &= 1\text{,}\\
  \euler(p^r) &= p^{r-1}(p-1) &\text{for $p$ prime, $r\ge1$,}\\
  \euler(nm) &= \euler(n)\euler(nm) &\text{when $\gcd(n,m)=1$.}
\end{align*}
The Euler function counts the number of generators of the cyclic group
with $n$ elements, thus, when the characteristic of the field does not
divide $n$, the number of primitive roots of unity is equal to $\euler(n)$.

\begin{theorem}
  Let $x$ be a primitive $n$-th root of unity in an algebraic closure
  of $\Q$, then
  \[[\Q(x):\Q]=\euler(n)\text{.}\]
\end{theorem}

If $x$ is an $n$-th root of unity, its minimal polynomial over $\Q$ is
called the $n$-th \index{cyclotomic~polynomial}\textit{cyclotomic
  polynomial} and is denoted by
$\Cyclo_n$\symb[f]{$\Cyclo_n$}{$n$-th Cyclotomic polynomial};
it is a monic polynomial with coefficients in $\Z$. $\Cyclo_n$ is an
irreducible factor of $X^n-1$ over $\Q$, its roots are all the
primitive $n$-th roots of unity, hence $\deg\Cyclo_n=\euler(n)$.

\pdfmcone{Removed the Galois requirement.}
Let $\LK/\K$ be a finite extension and let $x\in\LK$, the map
$M_x:a\mapsto xa$ is an automorphism of the $\K$-vector space
$\LK$. The minimal polynomial of its matrix with respect to any basis
is equal to the minimal polynomial of $x$ over $\K$.  The trace of
$M_x$ is called the \index{trace!of~an~element}\textit{trace} of $x$
and is denoted by
$\Tr_{\LK/\K}(x)$\symb[Tr]{$\Tr_{\LK/\K}$}{Trace of a field
  extension}; its determinant is called the \index{norm}\textit{norm}
of $x$ and is denoted by
$\Norm_{\LK/\K}(x)$\symb[Norm]{$\Norm_{\LK/\K}$}{Norm of a
  field extension}.

\begin{proposition}
  \label{th:basic-galois-theory:trace}
  Let $\LK/\K$ and $\K/k$ be field extensions and let
  $G=\Gal(\LK/\K)$. We have the following identities
  \begin{align*}
    \Tr_{\LK/\K}(x) &= \sum_{\sigma\in G}\sigma(x) \text{,}&
    \Tr_{\LK/k} &= \Tr_{\K/k}\circ\Tr_{\LK/\K}\text{,}\\
    \Norm_{\LK/\K}(x) &= \prod_{\sigma\in G}\sigma(x) \text{,}&
    \Norm_{\LK/k} &= \Norm_{\K/k}\circ\Norm_{\LK/\K}\text{.}
  \end{align*}
  The trace is a morphism of $\K$-vector spaces from $\LK$ to $\K$,
  the norm is a multiplicative morphism of groups from $\LK^\ast$ to
  $\K^\ast$.
\end{proposition}


\subsection{Finite fields}
\label{sec:basic-galois-theory:finite-fields}

Let $\K$ be a \index{finite~field} \textit{finite field}. It has
necessarily characteristic $p>0$, thus it must contain $\Z/p\Z$ as a
subfield. $\Z/p\Z$ is called the \index{prime~field}\textit{prime
  field} of $\K$ and is denoted by $\F_p$. Since $\K$ is a vector
space over $\F_p$, it must have cardinality $q=p^n$ for some $n$,
hence its multiplicative group has order $q-1$.

As a consequence, the elements of $\K^\ast$ must be roots of the
polynomial $X^{q-1}-1$. The fact that $p$ does not divide $q-1$
implies that $\K$ is the field of $\F_p[\zeta]$ where $\zeta$ is a
primitive $(q-1)$-th root of unity in $\clot{\F}_p$. This implies that,
up to isomorphism, there is an unique finite field containing $q$
elements, we denote by $\F_q$\symb[FiniteField]{$\F_q$}{Finite
  field of cardinality $q$} this field.

Using the same arguments, it is easy to show that for any $m\ge 1$,
$\F_{q^m}$ contains a subfield isomorphic to $\F_q$.  For any element
of $\F_q^m$, the mapping $\frob_q:x\mapsto
x^q$\symb[f]{$\frob_q$, $\frob$}{Frobenius automorphism} is a
morphism of fields that fixes $\F_q$, it is called the
\index{Frobenius!automorphism}\textit{Frobenius automorphism} of
$\F_{q^m}/\F_q$. We now give the main result about the Galois theory
of finite fields.

\begin{proposition}
  The Galois group of $\F_{q^m}/\F_q$ is a cyclic group of order $m$;
  it is generated by the Frobenius automorphism $\frob_q$.
\end{proposition}


\section{Basic algebraic geometry}
\label{sec:basic-algebr-geom}

\subsection{Noetherian rings}
\label{sec:noetherian-rings}
A ring $R$ is called \index{Noetherian~ring}\textit{Noetherian} if any
ascending chain of ideals eventually terminates. Being Noetherian is a
very stable condition: fields and principal ideal domains, quotients
of Noetherian rings, rings of polynomials in finitely many variables
over a Noetherian ring, are all Noetherian. In particular, all the
rings we will work with in this document are Noetherian.

\pdfmcone{Changed definition of primary ideal.}
A proper ideal $I$ is \index{ideal!maximal}\textit{maximal} if it is
not strictly contained in any proper ideal, this is equivalent to
$R/I$ being a field. A proper ideal is
\index{ideal!prime}\textit{prime} if $R/I$ is an integral domain;
\index{ideal!primary}\textit{primary} if $ab\in I$ implies that $a\in
I$ or $b^n\in I$ for some $n$. The
\index{ideal!radical}\textit{radical} of an ideal $I$ is the
ideal\symb[I]{$\sqrt{I}$}{Radical of an ideal}
\begin{equation}
  \label{eq:212}
  \sqrt{I} = \{f \,|\, f^r\in I \text{ for some $r\ge0$.}\}
  \text{.}
\end{equation}
An ideal is said to be radical if $\sqrt{I}=I$. The radical of a
primary ideal is prime.

\pdfmcone{Forgot strict inclusion for reducibility.}
An ideal $I$ is said to be \index{ideal!reducible}\textit{reducible}
if it is strictly contained in two ideals $I_1,I_2$ such that
$I=I_1\cap I_2$, \index{ideal!irreducible}\textit{irreducible}
otherwise. Any primary ideal is irreducible; we have the following two
fundamental results about reducibility.

\begin{proposition}
  Let $R$ be Noetherian. Any radical ideal $I$ admits an unique
  decomposition
  \begin{equation}
    \label{eq:213}
    I = P_1\cap\cdots\cap P_n
  \end{equation}
  with $P_i$ prime and $P_i\not\subset P_j$ for $i\ne j$.
\end{proposition}

\begin{theorem}[Primary decomposition]
  Let $R$ be Noetherian. \index{primary~decomposition}Any ideal $I$
  admits a decomposition
  \begin{equation}
    \label{eq:214}
    I = Q_1\cap\cdots\cap Q_n
  \end{equation}
  into primary ideals. Furthermore, $\sqrt{Q_i}$ is uniquely
  determined.
\end{theorem}

Now we state a fundamental lemma that we will repeatedly use in the
next chapters.

\begin{lemma}[Chinese remainder theorem]
  \label{th:chinese-remainder}
  Let $I_1,\ldots,I_n$ be pairwise coprime ideals (i.e.\ $I_i+I_j=R$ if
  $i\ne j$).  Then the canonical morphism $A\ra\prod_j A/I_j$ gives an
  isomorphism of rings
  \begin{equation}
    \label{eq:211}
    A/I_1\cap\cdots\cap I_n \isom \prod_j A/I_j
    \text{;}
  \end{equation}
  and the intersection $I_1\cap\cdots\cap I_n$ equals the product
  $I_1\cdots I_n$.
\end{lemma}


\subsection{Algebraic varieties}
\label{sec:algebraic-varieties}
\pdfmcone{Substituted the ambiguous use of "variety" with "set
  of zeros".}  We now consider the polynomial ring
$\K[x_1,\ldots,x_n]$, where $\K$ is a perfect field with algebraic
closure $\clot{\K}$. To any ideal $I$, we associate its \textit{set of
  zeros}
\begin{equation}
  \label{eq:215}
  V(I) = \{x\in\clot{\K}^n \,|\, f(x) = 0 \text{ for any } f\in I\}
  \text{.}
\end{equation}
\pdfmcone{Detailed definition of I(V), so that it is
  compatible with the version of the Nullstellensatz given later. }
Reciprocally, to any $V\subset\clot{\K}^n$ we associate the ideal
\begin{equation}
  \label{eq:216}
  I(V) = \{f\in\clot{\K}[x_1,\ldots,x_n] \,|\, f(x) = 0 \text{ for any } x\in V\}
  \text{.}
\end{equation}

\pdfmcone{Defined the affine space (and the projective space
  three paragraphs later).} A subset of $\clot{\K}^n$ is called an
\index{algebraic~set!affine}\textit{affine algebraic set} if it is the
set of zeros of an ideal of $\clot{\K}[x_1,\cdots,x_n]$.  The
\index{affine~space}\textit{affine space} of dimension $n$, denoted by
$\mathbb{A}^n$, is the affine algebraic set associated to the zero
ideal.

An algebraic set $V$ is
\index{algebraic~set!defined~over~a~field}\textit{defined over} $\K$
if $I(V)$ has a set of generators in $\K[x_1,\ldots,x_n]$; in this
case we denote by $V(\K)$ the subset $V\cap\K^n$.

An algebraic set is
\index{algebraic~set!irreducible}\textit{irreducible} if it cannot be
written as the union of two proper algebraic sets; equivalently, it is
irreducible if $I(V)$ is prime. An irreducible affine algebraic set is
called an \index{variety!affine}\textit{affine variety}.

There is also an equivalent notion of
\index{variety!projective}\textit{projective variety} for homogeneous
ideals. The projective variety associate to the zero ideal is called
the \index{projective~space}\textit{projective space} of dimension $n$,
and is denoted by $\Proj^n$.

In the sequel we shall drop the qualificatives ``affine'' or
``projective'', and simply speak of
\index{variety!algebraic}\textit{algebraic varieties} whenever
definitions/theorems are identical.


\begin{theorem}[Nullstellensatz]
  Let $I$ be an ideal and $V$ an algebraic set. We have the following
  identities
  \begin{equation}
    \label{eq:217}
    I(V(I)) = \sqrt{I}
    \text{,}\qquad
    V(I(V)) = V
    \text{.}
  \end{equation}
\end{theorem}

\pdfmcone{Made more explicit that V must be a variety.}
If $V$ is a variety defined over $\K$, its
\index{coordinate~ring}\textit{coordinate
  ring}\symb[KV]{$\K[V]$}{Coordinate ring of an algebraic
  variety} is
\begin{equation}
  \label{eq:218}
  \K[V] \eqdef \K[x_1,\ldots,x_n]/I(V)
  \text{;}
\end{equation}
the \index{function~field}\textit{function field}
$\K(V)$\symb[KV]{$\K(V)$}{Function field of an algebraic
  variety} is its field of fractions. 

The \index{dimension~of~a~variety}\textit{dimension} of a variety $V$
is the length $d$ of the longest chain of distinct non-empty
subvarieties of $V$
\begin{equation}
  \label{eq:219}
  V_d \subset \cdots \subset V_1 \subset V
  \text{.}
\end{equation}
Equivalently, it is the length of the longest strictly decreasing
chain of prime ideals in $\K[V]$. Still another way of defining it, is
the degree of transcendence of $\K(V)$ over $\K$.

If $V_1$ and $V_2$ are two varieties, a
\index{rational~map}\textit{affine rational map} is a map
\begin{equation}
  \label{eq:220}
  \begin{aligned}
    \phi : V_1&\ra V_2\text{,}\\
    x &\mapsto (f_1(x),\ldots,f_n(x))\text{,}
  \end{aligned}
\end{equation}
with $f_1,\ldots,f_n\in\clot{\K}(V_1)$ and such for any point $P$ at
which $f_1,\ldots,f_n$ are defined, $\phi(P)\in V_2$. An equivalent
definition exists for \textit{projective rational maps}.

A rational map that is defined at any point of $V_1$ is called a
\index{morphism~of~varieties}\textit{morphism}. A rational map (a
morphism) is
\index{rational~map!defined~over~a~field}\index{morphism!defined~over~a~field}\textit{defined
  over} $\K$ if $f_1,\ldots,f_n\in\K(V)$.



%%% Local Variables: 
%%% mode:flyspell
%%% ispell-local-dictionary:"american"
%%% mode: TeX-PDF
%%% mode: reftex
%%% TeX-master: "../these"
%%% End: 


